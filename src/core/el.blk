/***************************************************************************/
/*                                                                         */
/* Copyright 2020 INTERSEC SA                                              */
/*                                                                         */
/* Licensed under the Apache License, Version 2.0 (the "License");         */
/* you may not use this file except in compliance with the License.        */
/* You may obtain a copy of the License at                                 */
/*                                                                         */
/*     http://www.apache.org/licenses/LICENSE-2.0                          */
/*                                                                         */
/* Unless required by applicable law or agreed to in writing, software     */
/* distributed under the License is distributed on an "AS IS" BASIS,       */
/* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.*/
/* See the License for the specific language governing permissions and     */
/* limitations under the License.                                          */
/*                                                                         */
/***************************************************************************/

#include <sys/wait.h>
#include <pthread.h>
#include <lib-common/container-qheap.h>
#include <lib-common/container-qhash.h>
#include <lib-common/datetime.h>
#include <lib-common/str-buf-pp.h>
#include <lib-common/log.h>
#include <lib-common/el.h>
#include <lib-common/thr.h>

static pthread_mutex_t big_lock_g;
static bool use_big_lock_g = false;
struct rlimit fd_limit_g;

/** \addtogroup lc_el
 * \{
 */

/** \file lib-inet/el.c
 * \brief Event Loop module implementation.
 */

/*
 * TODO:
 *
 * - timer things:
 *   + monotonic clocks are very seldomly implemented (only on x86 for Linux).
 *     Have a way to detect timewarps, and avoid clock_gettime so that we can
 *     drop -lrt.
 *
 */

/* Arbitrary set default timeout to 59 seconds */
#define EL_LOOP_TIMEOUT  (59000)

/* {{{ Type declarations */

typedef enum ev_type_t {
    EV_UNUSED,
    EV_BLOCKER,
    EV_BEFORE,
    EV_SIGNAL,
    EV_CHILD,
    EV_FD,
    EV_TIMER,
    EV_PROXY,
    EV_IDLE,
    EV_FS_WATCH,
    EV_WAKE,
} ev_type_t;

enum ev_flags_t {
    EV_FLAG_REFS          = (1U <<  0),
    EV_FLAG_TRACE         = (1U <<  1),
    EV_FLAG_IS_BLK        = (1U <<  2),

    EV_FLAG_TIMER_NOMISS  = (1U <<  8),
    EV_FLAG_TIMER_LOWRES  = (1U <<  9),
    EV_FLAG_TIMER_UPDATED = (1U << 10),

    EV_FLAG_FD_WATCHED    = (1U <<  8),
    EV_FLAG_FD_FIRED      = (1U <<  9),

    EV_FLAG_FSW_ACTIVE    = (1U <<  8),
#define EV_FLAG_HAS(ev, f)   ((ev)->flags & EV_FLAG_##f)
#define EV_FLAG_SET(ev, f)   ((ev)->flags |= EV_FLAG_##f)
#define EV_FLAG_RST(ev, f)   ((ev)->flags &= ~EV_FLAG_##f)

#ifndef NDEBUG
#define EV_IS_TRACED(ev)   unlikely(EV_FLAG_HAS(ev, TRACE))
#else
#define EV_IS_TRACED(ev)   0
#endif
};

typedef struct ev_t {
    uint8_t   type;             /* ev_type_t */
    uint8_t   generation;
    uint16_t  flags     : 14;
    uint16_t  priority  : 2;
    union {
        uint16_t  events_avail; /* EV_PROXY */
        uint16_t  events_act;   /* EV_FD    */
    };
    uint16_t  events_wanted;    /* EV_PROXY, EV_FD */

    union {
        el_cb_f       *cb;
        el_signal_f   *signal;
        el_child_f    *child;
        el_fd_f       *fd;
        el_proxy_f    *prox;
        el_fs_watch_f *fs_watch;

        el_cb_b       cb_blk;
        el_signal_b   signal_blk;
        el_child_b    child_blk;
        el_fd_b       fd_blk;
        el_proxy_b    proxy_blk;
        el_fs_watch_b fs_watch_blk;
    } cb;
    union {
        data_t priv;
        block_t   wipe;
    };

    dlist_t ev_list;            /* EV_BEFORE, EV_SIGNAL, EV_PROXY, EV_FD */
    union {
        struct {                /* EV_FD */
            int     fd;
            bool    owned;
            uint8_t generation;
        } fd;
        struct {
            pid_t   pid;
            int     status;
            bool    has_exited;
        } child;                /* EV_CHILD */
        struct {
            uint64_t expiry;
            int64_t  repeat;
            int      tolerance;
            int      heappos;
        } timer;                /* EV_TIMER */
        struct {
            char *path;
            data_t ctx;
        } fs_watch;             /* EV_FS_WATCH */
        struct {
            el_t read_fd;
            int  write_fd;
            bool use_eventfd;
        } wake;                 /* EV_WAKE */
        uint8_t   signo;        /* EV_SIGNAL */
    };
} ev_t;

#define TIMER_TOLERATED_EXPIRY(ev)  ({                                       \
        const ev_t *__tte_ev = (ev);                                         \
        __tte_ev->timer.expiry + __tte_ev->timer.tolerance;                  \
    })

#define TIMER_CMP(ev1, op, ev2)  \
    TIMER_TOLERATED_EXPIRY(ev1) op TIMER_TOLERATED_EXPIRY(ev2)

static ALWAYS_INLINE void ev_set_qhp_pos(ev_t *ev, int pos)
{
    ev->timer.heappos = pos;
}

qvector_t(ev, ev_t *);
qhp_min_t(timer, ev_t *, TIMER_CMP, ev_set_qhp_pos);
qm_k32_t(ev_assoc, ev_t *);
qm_k64_t(ev, ev_t *);

/* }}} */

static struct {
    volatile uint32_t gotsigs;
    int       active;         /* number of ev_t keeping the el_loop running */
    int       used;           /* number of ev_t currently used              */
    uint8_t   unloop;         /* @see el_unloop()                           */
    int       loop_depth;     /* depth of el_loop_timeout() recursion       */

    dlist_t   idle;           /* ev_t to run when we're "idle"              */
    dlist_t   idle_parked;    /* list to hide idle hooks for a while        */
    dlist_t   before;         /* ev_t to run just before the epoll call     */
    dlist_t   sigs;           /* signals el_t's                             */
    dlist_t   proxy, proxy_ready;
    dlist_t   fired;          /* fds with applicative pending events        */
    qhp_t(timer) timers;      /* relative timers heap (see comments after)  */
    qv_t(ev)  cache;
    qm_t(ev_assoc) childs;    /* el_t's watching for processes              */
    qm_t(ev)  fd_act;         /* el_t's timers to el_t fds map              */
    el_worker_f *worker;      /* worker callback                            */
    uint64_t     worker_end;  /* worker end time                            */

    el_t el_on_pwr;
    el_t el_sigchld_hook;

    bool  has_run        : 1; /* true if we did something during a loop    */
    bool  worker_running : 1; /* true if the worker is currently running   */
    bool  terminating    : 1; /* have we received a termination signal?    */

    /*----- allocation stuff -----*/
#define EV_ALLOC_FACTOR     10   /* basic segment is 1024 events            */
#define EVS_NB_MAX_BUCKETS  (32 - EV_ALLOC_FACTOR)
    qv_t(ev) buckets;
    ev_t    *evs_alloc_next, *evs_alloc_end;
    dlist_t evs_free;
    dlist_t evs_gc;
    logger_t logger;
    logger_t tracing_logger;
} el_g = {
#define _G el_g
    .idle           = DLIST_INIT(_G.idle),
    .idle_parked    = DLIST_INIT(_G.idle_parked),
    .before         = DLIST_INIT(_G.before),
    .sigs           = DLIST_INIT(_G.sigs),
    .proxy          = DLIST_INIT(_G.proxy),
    .proxy_ready    = DLIST_INIT(_G.proxy_ready),
    .evs_free       = DLIST_INIT(_G.evs_free),
    .evs_gc         = DLIST_INIT(_G.evs_gc),
    .fired          = DLIST_INIT(_G.fired),
    .childs         = QM_INIT(ev_assoc, _G.childs),
    .fd_act         = QM_INIT(ev, _G.fd_act),
    .logger         = LOGGER_INIT_INHERITS(NULL, "el"),
    .tracing_logger = LOGGER_INIT_SILENT_INHERITS(&_G.logger, "tracing"),
};

#define ASSERT(msg, expr)  assert (((void)msg, likely(expr)))
#define CHECK_EV(ev)   \
    ASSERT("ev is uninitialized", (ev)->type)
#define CHECK_EV_TYPE(ev, typ) \
    ASSERT("incorrect type", (ev)->type == typ)

static const char *ev_type_to_str(ev_type_t type)
{
    switch (type) {
      case EV_UNUSED:   return "unused";
      case EV_BLOCKER:  return "blocker";
      case EV_BEFORE:   return "before loop";
      case EV_SIGNAL:   return "signal";
      case EV_CHILD:    return "child";
      case EV_FD:       return "file desc.";
      case EV_TIMER:    return "timer";
      case EV_PROXY:    return "proxy";
      case EV_IDLE:     return "idle";
      case EV_FS_WATCH: return "fs watch";
      case EV_WAKE:     return "wake";
    }
    return "unknown";
}

static ev_t *ev_add(dlist_t *l, ev_t *ev)
{
    dlist_add(l, &ev->ev_list);
    return ev;
}

__must_check__
static uint8_t ev_cache_list(dlist_t *l)
{
    static uint8_t generation = 1;
    ev_t *ev;

    generation += 2;
    qv_clear(&_G.cache);
    dlist_for_each_entry(ev, l, ev_list) {
        ev->generation = generation;
        qv_append(&_G.cache, ev);
    }
    return generation;
}

static ev_t *el_create(ev_type_t type, void *cb, data_t priv, bool ref)
{
    ev_t *res;

    if (unlikely(dlist_is_empty(&_G.evs_free))) {
        if (unlikely(_G.evs_alloc_next >= _G.evs_alloc_end)) {
            int   bucket_len = 1 << (_G.buckets.len + EV_ALLOC_FACTOR);
            ev_t *bucket     = p_new(ev_t, bucket_len);

            qv_append(&_G.buckets, bucket);
            if (unlikely(_G.buckets.len > EVS_NB_MAX_BUCKETS)) {
                e_panic(E_PREFIX("insane amount of events"));
            }
            _G.evs_alloc_next = bucket;
            _G.evs_alloc_end  = bucket + bucket_len;
        }
        res = _G.evs_alloc_next++;
    } else {
        res = container_of(_G.evs_free.next, ev_t, ev_list);
        dlist_remove(&res->ev_list);
    }

    *res = (ev_t){
        .type   = type,
        .cb.cb  = cb,
    };
    res->priv = priv;
    dlist_init(&res->ev_list);

    logger_trace(&_G.logger, 2, "creating event %p (%s)",
                 res, ev_type_to_str(res->type));
    assert (MODULE_IS_LOADED(el) || MODULE_IS_INITIALIZING(el));

    _G.used++;
    return ref ? el_ref(res) : res;
}

static ev_t *el_blk_register(ev_t *ev, void *cb, block_t wipe)
{
    el_cb_b blk = cb;

    EV_FLAG_SET(ev, IS_BLK);
    ev->cb.cb_blk = Block_copy(blk);
    ev->wipe      = wipe ? Block_copy(wipe) : NULL;
    return ev;
}

static void __el_unref(ev_t *ev)
{
    if (EV_FLAG_HAS(ev, REFS)) {
        _G.active--;
        EV_FLAG_RST(ev, REFS);
    }
}

static data_t el_destroy(ev_t **evp)
{
    ev_t *ev = *evp;

    logger_trace(&_G.logger, 2, "destroying event %p (%s)",
                 ev, ev_type_to_str(ev->type));
    assert (MODULE_IS_LOADED(el) || MODULE_IS_SHUTTING_DOWN(el));
    assert (!MODULE_IS_LOADED(thr) || thr_is_on_queue(thr_queue_main_g));

    if (EV_FLAG_HAS(ev, IS_BLK)) {
        block_t wipe = ev->wipe;

        if (wipe) {
            wipe();
            Block_release(wipe);
        }
        Block_release(ev->cb.cb);
        EV_FLAG_RST(ev, IS_BLK);
        ev->priv = (data_t)NULL;
    }
    __el_unref(ev);
    dlist_move(&_G.evs_gc, &ev->ev_list);
    ev->generation = 0;
    ev->type  = EV_UNUSED;
    ev->flags = 0;
    *evp = NULL;
    _G.used--;
    return ev->priv;
}

static void el_child_fire(ev_t **ev)
{
    ev_t *e = *ev;

    if (EV_FLAG_HAS(e, IS_BLK)) {
        e->cb.child_blk(e, e->child.pid, e->child.status);
    } else {
        (*e->cb.child)(e, e->child.pid, e->child.status, e->priv);
    }
    MODULE_METHOD_RUN_INT(at_fork_on_child_terminated, e->child.pid);
    el_destroy(&e);
}

/* {{{ blockers, before and idle events */

ev_t *el_blocker_register(void)
{
    return el_create(EV_BLOCKER, NULL, (data_t)NULL, true);
}

ev_t *el_before_register_d(el_cb_f *cb, data_t priv)
{
    return ev_add(&_G.before, el_create(EV_BEFORE, cb, priv, true));
}

ev_t *el_before_register_blk(el_cb_b blk, block_t wipe)
{
    return el_blk_register(el_before_register((void *)-1, NULL), blk, wipe);
}

void el_before_set_hook(el_t ev, el_cb_f *cb)
{
    CHECK_EV_TYPE(ev, EV_BEFORE);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.cb = cb;
}

static void el_before_process(void)
{
    uint8_t generation;

    generation = ev_cache_list(&_G.before);

    tab_for_each_entry(ev, &_G.cache) {
        if (ev->generation != generation) {
            continue;
        }

        if (ev->type == EV_UNUSED) {
            /* ev has been unregistered by a previous ev on the list.
             */
            continue;
        }

        if (unlikely(ev->type == EV_CHILD)) {
            /* XXX: this can happen when registering a child which is already
             *      dead, cf. el_child_register_d. */
            el_child_fire(&ev);
            continue;
        }

        CHECK_EV_TYPE(ev, EV_BEFORE);
        if (EV_FLAG_HAS(ev, IS_BLK)) {
            ev->cb.cb_blk(ev);
        } else {
            (*ev->cb.cb)(ev, ev->priv);
        }
    }
}

ev_t *el_idle_register_d(el_cb_f *cb, data_t priv)
{
    return ev_add(&_G.idle, el_create(EV_IDLE, cb, priv, false));
}

ev_t *el_idle_register_blk(el_cb_b blk, block_t wipe)
{
    return el_blk_register(el_idle_register((void *)-1, NULL), blk, wipe);
}

void el_idle_set_hook(el_t ev, el_cb_f *cb)
{
    CHECK_EV_TYPE(ev, EV_IDLE);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.cb = cb;
}

void el_idle_unpark(ev_t *ev)
{
    CHECK_EV_TYPE(ev, EV_IDLE);
    dlist_move(&_G.idle, &ev->ev_list);
}

static void el_idle_process(uint64_t now)
{
    static uint64_t last_run = UINT64_MAX;

    if (now - last_run > 10 * 60 * 1000)
        dlist_splice_tail(&_G.idle, &_G.idle_parked);
    if (!_G.has_run) {
        uint32_t generation = ev_cache_list(&_G.idle);

        dlist_splice(&_G.idle_parked, &_G.idle);
        last_run = now;

        tab_for_each_entry(ev, &_G.cache) {
            if (ev->generation != generation) {
                continue;
            }

            CHECK_EV_TYPE(ev, EV_IDLE);
            if (EV_FLAG_HAS(ev, IS_BLK)) {
                ev->cb.cb_blk(ev);
            } else {
                (*ev->cb.cb)(ev, ev->priv);
            }
        }
    }
}

/* }}} */
/* {{{ signal events */

static const char *si_code_to_str(int signum, int si_code)
{
#define CASE(_code)  case _code: return TOSTR(_code)

    switch (signum) {
      case SIGILL:
        switch (si_code) {
          CASE(ILL_ILLOPC);
          CASE(ILL_ILLOPN);
          CASE(ILL_ILLADR);
          CASE(ILL_ILLTRP);
          CASE(ILL_PRVOPC);
          CASE(ILL_PRVREG);
          CASE(ILL_COPROC);
          CASE(ILL_BADSTK);
        }
        break;

      case SIGFPE:
        switch (si_code) {
          CASE(FPE_INTDIV);
          CASE(FPE_INTOVF);
          CASE(FPE_FLTDIV);
          CASE(FPE_FLTOVF);
          CASE(FPE_FLTUND);
          CASE(FPE_FLTRES);
          CASE(FPE_FLTINV);
          CASE(FPE_FLTSUB);
        }
        break;

      case SIGSEGV:
        switch (si_code) {
          CASE(SEGV_MAPERR);
          CASE(SEGV_ACCERR);
        }
        break;

      case SIGBUS:
        switch (si_code) {
          CASE(BUS_ADRALN);
          CASE(BUS_ADRERR);
          CASE(BUS_OBJERR);
#ifdef BUS_MCEERR_AR
          CASE(BUS_MCEERR_AR);
#endif
#ifdef BUS_MCEERR_AO
          CASE(BUS_MCEERR_AO);
#endif
        }
        break;

      case SIGTRAP:
        switch (si_code) {
          CASE(TRAP_BRKPT);
          CASE(TRAP_TRACE);
        }
        break;

      case SIGCHLD:
        switch (si_code) {
          CASE(CLD_EXITED);
          CASE(CLD_KILLED);
          CASE(CLD_DUMPED);
          CASE(CLD_TRAPPED);
          CASE(CLD_STOPPED);
          CASE(CLD_CONTINUED);
        }
        break;

#ifdef SIGPOLL
      case SIGPOLL:
        switch (si_code) {
          CASE(POLL_IN);
          CASE(POLL_OUT);
          CASE(POLL_MSG);
          CASE(POLL_ERR);
          CASE(POLL_PRI);
          CASE(POLL_HUP);
        }
        break;
#endif

      default:
        switch (si_code) {
          CASE(SI_USER);
#ifdef SI_KERNEL
          CASE(SI_KERNEL);
#endif
          CASE(SI_QUEUE);
          CASE(SI_TIMER);
          CASE(SI_MESGQ);
          CASE(SI_ASYNCIO);
#ifdef SI_SIGIO
          CASE(SI_SIGIO);
#endif
#ifdef SI_TKILL
          CASE(SI_TKILL);
#endif
        }
        break;
    }
#undef CASE

    return "unknown";
}

static bool signal_is_terminating(int signo)
{
    return signo == SIGTERM || signo == SIGINT || signo == SIGQUIT
        || signo == SIGUSR2;
}

static void el_sighandler(int signum, siginfo_t *siginfo, void *ctx)
{
    _G.gotsigs |= (1 << signum);

    if (signal_is_terminating(signum)) {
        _G.terminating = true;
    }

    /* Refer to 'man 2 sigaction' for the meaning of the codes. */
    logger_trace(&_G.logger, 1,
                 "received signal %d from PID %d, UID %d (code %s)",
                 signum, siginfo->si_pid, siginfo->si_uid,
                 si_code_to_str(signum, siginfo->si_code));
}

static void el_signal_process(void)
{
    uint8_t generation;
    uint32_t gotsigs = _G.gotsigs;
    struct timeval now;

    if (!gotsigs)
        return;

    _G.gotsigs &= ~gotsigs;
    lp_gettv(&now);

    generation = ev_cache_list(&_G.sigs);
    tab_for_each_entry(ev, &_G.cache) {
        int signo;

        if (ev->generation != generation) {
            continue;
        }

        CHECK_EV_TYPE(ev, EV_SIGNAL);

        signo = ev->signo;
        if (gotsigs & (1 << signo)) {
            if (signal_is_terminating(signo)) {
                module_on_term(signo);
            }
            if (EV_FLAG_HAS(ev, IS_BLK)) {
                ev->cb.signal_blk(ev, signo);
            } else {
                (*ev->cb.signal)(ev, signo, ev->priv);
            }
            _G.has_run = true;
        }
    }
}

static bool el_signal_has_pending_events(void)
{
    return _G.gotsigs;
}

void el_signal_set_hook(el_t ev, el_signal_f *cb)
{
    CHECK_EV_TYPE(ev, EV_SIGNAL);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.signal = cb;
}

ev_t *el_signal_register_d(int signo, el_signal_f *cb, data_t priv)
{
    struct sigaction sa;
    ev_t *ev;

    p_clear(&sa, 1);
    sa.sa_sigaction = el_sighandler;
    sigfillset(&sa.sa_mask);
    sa.sa_flags = SA_RESTART | SA_SIGINFO;
    sigaction(signo, &sa, NULL);

    ev = el_create(EV_SIGNAL, cb, priv, false);
    ev->signo = signo;
    return ev_add(&_G.sigs, ev);
}

ev_t *el_signal_register_blk(int signo, el_signal_b blk, block_t wipe)
{
    return el_blk_register(el_signal_register(signo, (void *)-1, NULL), blk,
                           wipe);
}

/* }}} */
/* {{{ child events */

typedef struct ev_sigchld_assoc_t {
    int pid;
    ev_t *child;
} ev_sigchld_assoc_t;

qvector_t(ev_sigchld_assoc, ev_sigchld_assoc_t);

static void el_sigchld_hook(ev_t *ev, int signo, data_t priv)
{
    t_scope;
    qv_t(ev_sigchld_assoc) ev_assocs;

    t_qv_init(&ev_assocs, qm_len(ev_assoc, &_G.childs));

    /* XXX the callback called by el_child_fire or the module method
     * at_fork_on_child_terminated may change the global qm `_G.childs`, so we
     * cannot call them while iterating on the qm and removing elements from
     * it.
     * We first need to list the dead child processes, and then call
     * el_child_fire() or the module method at_fork_on_child_terminated in
     * another loop.
     */
    qm_for_each_pos(ev_assoc, pos, &_G.childs) {
        ev_sigchld_assoc_t ev_assoc;
        int status;

        ev_assoc.pid = _G.childs.keys[pos];
        if (waitpid(ev_assoc.pid, &status, WNOHANG) == ev_assoc.pid) {
            /* The child process is dead. */
            ev_assoc.child = _G.childs.values[pos];
            if (likely(ev_assoc.child)) {
                ev_assoc.child->child.status = status;
            }
            qv_append(&ev_assocs, ev_assoc);
            qm_del_at(ev_assoc, &_G.childs, pos);
        }
    }

    t_seal();

    tab_for_each_ptr(ev_assoc, &ev_assocs) {
        if (likely(ev_assoc->child)) {
            el_child_fire(&ev_assoc->child);
        } else {
            MODULE_METHOD_RUN_INT(at_fork_on_child_terminated, ev_assoc->pid);
        }
    }
}

static void el_sigchld_register(void)
{
    if (unlikely(!_G.el_sigchld_hook)) {
        _G.el_sigchld_hook = el_signal_register(SIGCHLD, el_sigchld_hook,
                                                NULL);
    }
}

static void el_child_at_fork_on_parent(pid_t pid)
{
    if (pid < 0) {
        /* Do nothing if it doesn't come from ifork(). */
        return;
    }

    /* Watch pid without an el.
     * This way, we can call at_fork_on_child_terminated without having to do
     * a el_child_register() in el_sigchld_hook(). */
    if (qm_add(ev_assoc, &_G.childs, pid, NULL) < 0) {
        ASSERT("pid is already watched", false);
    }

    el_sigchld_register();
}

void el_child_set_hook(el_t ev, el_child_f *cb)
{
    CHECK_EV_TYPE(ev, EV_CHILD);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.child = cb;
}

ev_t *el_child_register_d(pid_t pid, el_child_f *cb, data_t priv)
{
    uint32_t pos;
    sigset_t set;
    sigset_t prev;
    int status;

    ev_t *ev = el_create(EV_CHILD, cb, priv, true);

    assert (pid > 0);
    ev->child.pid = pid;
    ev->child.has_exited = false;

    pos = qm_put(ev_assoc, &_G.childs, pid, ev, 0);
    /* It is likely that the child process comes from ifork(). */
    if (likely(pos & QHASH_COLLISION)) {
        pos ^= QHASH_COLLISION;
        ASSERT("pid is already watched", !_G.childs.values[pos]);
        _G.childs.values[pos] = ev;
    }

    sigemptyset(&set);
    sigaddset(&set, SIGCHLD);

    pthread_sigmask(SIG_BLOCK, &set, &prev);

    if (waitpid(pid, &status, WNOHANG) > 0) {
        /* The process is already dead */
        if (qm_del_key(ev_assoc, &_G.childs, ev->child.pid) < 0) {
            ASSERT("event not found", false);
        }
        ev->child.status = status;
        ev->child.has_exited = true;

        pthread_sigmask(SIG_SETMASK, &prev, NULL);
        return ev_add(&_G.before, ev);
    }

    el_sigchld_register();
    pthread_sigmask(SIG_SETMASK, &prev, NULL);
    return ev;
}

ev_t *el_child_register_blk(pid_t pid, el_child_b blk, block_t wipe)
{
    return el_blk_register(el_child_register(pid, (void *)-1, NULL), blk, wipe);
}

static data_t el_child_unregister(ev_t **evp)
{
    if (*evp) {
        CHECK_EV_TYPE(*evp, EV_CHILD);
        if (qm_del_key(ev_assoc, &_G.childs, (*evp)->child.pid) < 0) {
            if (!(*evp)->child.has_exited) {
                ASSERT("event not found", false);
            }
        }
        return el_destroy(evp);
    }
    return (data_t)NULL;
}

pid_t el_child_getpid(el_t ev)
{
    CHECK_EV_TYPE(ev, EV_CHILD);
    return ev->child.pid;
}

int el_child_get_status(el_t ev)
{
    CHECK_EV_TYPE(ev, EV_CHILD);
    return ev->child.status;
}

el_t el_child_get_el(pid_t pid)
{
    return qm_get_def(ev_assoc, &_G.childs, pid, NULL);
}

pid_t el_spawn_child(const char *file, const char *argv_in[],
                     const char *envp[], block_t child, el_child_b blk,
                     block_t wipe)
{
    pid_t pid;
    qv_t(cstr) argv_final;

    qv_init(&argv_final);
    qv_append(&argv_final, file);

    {
        logger_debug_scope(&_G.tracing_logger);
        const char **ptr = &argv_in[0];

        logger_cont("running command %s", file);
        while (*ptr) {
            logger_cont(" %s", *ptr);
            qv_append(&argv_final, *ptr);

            ptr++;
        }
    }

    qv_append(&argv_final, NULL);

    if ((pid = ifork()) == 0) {
        if (child) {
            child();
        }
        if (envp) {
            /* XXX we cannot use execvpe which appeared in glibc 2.11 since
             * centos 5 only has gblic 2.5 */
            environ = (char **)envp;
        }
        execvp(file, (char **)argv_final.tab);
        logger_fatal(&_G.logger, "unable to execute `%s`: %m", file);
    } else
    if (pid < 0) {
        logger_fatal(&_G.logger,
                     "unable to fork `%s` in the background: %m", file);
    }
    qv_wipe(&argv_final);
    el_child_register_blk(pid, blk, wipe);
    return pid;
}

typedef struct spawn_child_capture_t {
    pid_t pid;

    /* stdout/stderr capture. */
    sb_t out;
    el_t capture;

    /* Timeout. */
    el_t timer;
    int next_sig;

    /* Callbacks. */
    block_t child;
    el_child_output_b blk;
    block_t wipe;
} spawn_child_capture_t;

static inline spawn_child_capture_t *
spawn_child_capture_init(spawn_child_capture_t *ctx)
{
    p_clear(ctx, 1);
    sb_init(&ctx->out);
    return ctx;
}
GENERIC_NEW(spawn_child_capture_t, spawn_child_capture);
static inline void spawn_child_capture_wipe(spawn_child_capture_t *ctx)
{
    sb_wipe(&ctx->out);
    el_unregister(&ctx->capture);
    el_unregister(&ctx->timer);
    Block_release_p(&ctx->child);
    Block_release_p(&ctx->blk);
    Block_release_p(&ctx->wipe);
}
GENERIC_DELETE(spawn_child_capture_t, spawn_child_capture);

static int spawn_child_capture_on_output(el_t el, int fd, short event,
                                         data_t data)
{
    spawn_child_capture_t *ctx = data.ptr;

    IGNORE(sb_read(&ctx->out, fd, 0));
    return 0;
}

static void spawn_child_timeout(el_t el, data_t data)
{
    spawn_child_capture_t *ctx = data.ptr;

    if (killpg(ctx->pid, ctx->next_sig) < 0) {
        if (errno == ESRCH) {
            /* No process can be found in the process group. This can happen
             * if the timeout is very low and the system is under stress,
             * because there is a race with the creation of the process group
             * in the child. In that case, no need to change the signal. */
            return;
        }
    }
    if (ctx->next_sig == SIGINT) {
        ctx->next_sig = SIGTERM;
    } else {
        ctx->next_sig = SIGKILL;
    }
}

pid_t el_spawn_child_capture(const char *file,
                             const char *argv[],
                             const char *envp[],
                             int timeout,
                             block_t child,
                             el_child_output_b blk,
                             block_t wipe)
{
    spawn_child_capture_t *ctx = spawn_child_capture_new();
    int pfd[2];
    int *pfd_ptr = pfd;

    if (pipe(pfd) < 0) {
        logger_fatal(&_G.logger,
                     "unable to execute `%s`: cannot prepare out fds", file);
    }

    ctx->blk = Block_copy(blk);
    if (child) {
        ctx->child = Block_copy(child);
    }
    if (wipe) {
        ctx->wipe = Block_copy(wipe);
    }

    ctx->pid = el_spawn_child(file, argv, envp, ^{
        qv_t(u32) fds_to_keep;

        setpgid(0, 0); /* Create a process group id. */
        p_close(&pfd_ptr[0]);

        qv_inita(&fds_to_keep, 1);
        qv_append(&fds_to_keep, pfd_ptr[1]);
        close_fds(STDIN_FILENO, &fds_to_keep);

        dup2(pfd_ptr[1], STDOUT_FILENO);
        dup2(pfd_ptr[1], STDERR_FILENO);
        p_close(&pfd_ptr[1]);

        devnull_dup(STDIN_FILENO);

        if (ctx->child) {
            ctx->child();
        }
    }, ^(el_t el, pid_t _pid, int status) {
        spawn_child_capture_on_output(ctx->capture,
                                      el_fd_get_fd(ctx->capture),
                                      POLLIN, (data_t){ .ptr = ctx });
        ctx->blk(el, _pid, status, LSTR_SB_V(&ctx->out));
    }, ^{
        spawn_child_capture_t *_ctx = ctx;

        if (ctx->wipe) {
            ctx->wipe();
        }
        spawn_child_capture_delete(&_ctx);
    });

    p_close(&pfd[1]);
    fd_set_features(pfd[0], O_NONBLOCK);

    if (timeout > 0) {
        ctx->next_sig = SIGINT;
        ctx->timer = el_timer_register(timeout, timeout, EL_TIMER_LOWRES,
                                       &spawn_child_timeout, ctx);
    }
    ctx->capture = el_fd_register(pfd[0], true, POLLIN,
                                  &spawn_child_capture_on_output, ctx);

    return ctx->pid;
}

/* }}} */
/* {{{ timer events */

/*
 * timers are extremely efficient, and use a binary-min-heap as a base
 * structure.
 *
 * Binary min-heaps are balanced binary trees stored in an array.
 * The invariant is that the "label" (for us the millisecond the timer has to
 * start at) of each parent node, is smaller than any of its children ones.
 *
 * Hence the next to be run timer is the root of the heap.
 *
 * Adding/Updating/... a timer is pseudo linear O(log(n)) in the number of
 * timers.
 */

static data_t el_timer_unregister(ev_t **evp)
{
    if (unlikely(!*evp))
        return (data_t)NULL;

    qhp_remove(timer, &_G.timers, (*evp)->timer.heappos);

    return el_destroy(evp);
}

static int el_timer_next_expiration(int timeout, uint64_t clk)
{
    if (!qhp_is_empty(timer, &_G.timers)) {
        uint64_t nxt = TIMER_TOLERATED_EXPIRY(qhp_first(timer, &_G.timers));

        if (nxt < (uint64_t)timeout + clk) {
            return MAX(0, (int)(nxt - clk));
        }
    }
    return timeout;
}

static void el_timer_process(uint64_t until)
{
    struct timeval tv;

    lp_gettv(&tv);
    while (!qhp_is_empty(timer, &_G.timers)) {
        ev_t *ev = qhp_first(timer, &_G.timers);

        ASSERT("should be a timer", ev->type == EV_TIMER);
        if (ev->timer.expiry > until) {
            return;
        }

        logger_trace(&_G.logger, 3, "trigger timer %p", ev);

        EV_FLAG_RST(ev, TIMER_UPDATED);
        if (EV_FLAG_HAS(ev, IS_BLK)) {
            ev->cb.cb_blk(ev);
        } else {
            (*ev->cb.cb)(ev, ev->priv);
        }
        _G.has_run = true;

        /* ev has been unregistered in (*cb) */
        if (ev->type == EV_UNUSED) {
            continue;
        }

        if (ev->timer.repeat > 0) {
            ev->timer.expiry += ev->timer.repeat;
            if (!EV_FLAG_HAS(ev, TIMER_NOMISS) && ev->timer.expiry < until) {
                uint64_t delta  = until - ev->timer.expiry;

                ev->timer.expiry += ROUND_UP(delta, (uint64_t)ev->timer.repeat);
            }
            __qhp_down(timer, &_G.timers, ev->timer.heappos);
        } else
        if (!EV_FLAG_HAS(ev, TIMER_UPDATED)) {
            el_timer_unregister(&ev);
        }
    }
}

static uint64_t get_clock(void)
{
    struct timespec ts;
    int res;

#if   defined(CLOCK_MONOTONIC) /* POSIX   */
    res = clock_gettime(CLOCK_MONOTONIC, &ts);
#else
#   error you need to find out how to get a monotonic clock for your system
#endif
    assert (res == 0);
    return 1000ull * ts.tv_sec + ts.tv_nsec / 1000000;
}

static bool el_timer_has_pending_events(void)
{
    ev_t *ev;
    uint64_t now = 0;

    if (!qhp_is_empty(timer, &_G.timers) || _G.worker_running) {
        now = get_clock();
    }

    if (_G.worker_running) {
        if (_G.worker_end <= now) {
            return true;
        }
    }

    if (qhp_is_empty(timer, &_G.timers)) {
        return false;
    }

    ev = qhp_first(timer, &_G.timers);
    return ev->timer.expiry <= now;
}

static void el_timer_compute_tolerance(ev_t *ev)
{
    int64_t repeat = ev->timer.repeat;

    if (repeat < 0) {
        repeat = -repeat;
    }

    /* XXX: we consider that timer rescheduled in more than half a second
     *      don't care about high resolution.
     */
    if (!EV_FLAG_HAS(ev, TIMER_LOWRES) && repeat < 500) {
        ev->timer.tolerance = 0;
        return;
    }

    /* Low-resolution timer allow a shift of up to 10% of the timer duration.
     * That shift is actually capped at EL_LOOP_TIMEOUT since this is the
     * duration of an event loop in case of inactivity.
     */
    ev->timer.tolerance = MIN(repeat / 10, EL_LOOP_TIMEOUT);
}

ev_t *el_timer_register_d(int64_t next, int64_t repeat,
                          ev_timer_flags_t flags, el_cb_f *cb, data_t priv)
{
    ev_t *ev = el_create(EV_TIMER, cb, priv, true);

    if (flags & EL_TIMER_NOMISS) {
        EV_FLAG_SET(ev, TIMER_NOMISS);
    }
    if (flags & EL_TIMER_LOWRES) {
        EV_FLAG_SET(ev, TIMER_LOWRES);
    }
    if (repeat > 0) {
        ev->timer.repeat = repeat;
    } else {
        ev->timer.repeat = -next;
    }
    el_timer_compute_tolerance(ev);
    ev->timer.expiry = (uint64_t)next + get_clock();
    qhp_insert(timer, &_G.timers, ev);

    if (logger_is_traced(&_G.logger, 2)) {
        logger_trace_scope(&_G.logger, 2);
        bool one_shot = ev->timer.repeat < 0;

        logger_cont("register %stimer on event %p ",
                    one_shot ? "one shot " : "", ev);
        logger_cont("(next: %jdms, ", next);
        if (!one_shot) {
            logger_cont("expiry: %ju.%03ju, ",
                        ev->timer.expiry / 1000,
                        ev->timer.expiry % 1000);
        }
        logger_cont("tolerance: %ums, ", ev->timer.tolerance);
        logger_cont("cb: %p)", (void *)ev->cb.cb);
    }

    return ev;
}

ev_t *el_timer_register_blk(int64_t next, int64_t repeat,
                            ev_timer_flags_t flags, el_cb_b blk, block_t wipe)
{
    return el_blk_register(el_timer_register(next, repeat, flags, (void *)-1,
                                             NULL),
                           blk, wipe);
}

void el_timer_set_hook(el_t ev, el_cb_f *cb)
{
    CHECK_EV_TYPE(ev, EV_TIMER);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.cb = cb;
}

static ALWAYS_INLINE void el_timer_restart_fast(ev_t *ev, uint64_t restart)
{
    ev->timer.expiry = (uint64_t)restart + get_clock();
    EV_FLAG_SET(ev, TIMER_UPDATED);
    qhp_fixup(timer, &_G.timers, ev->timer.heappos);

    logger_trace(&_G.logger, 3,
                 "restart timer %p (restart: %jums, expiry: %ju.%03ju)",
                 ev, restart,
                 ev->timer.expiry / 1000,
                 ev->timer.expiry % 1000);
}

void el_timer_restart(ev_t *ev, int64_t restart)
{
    CHECK_EV_TYPE(ev, EV_TIMER);
    ASSERT("timer isn't a oneshot timer", ev->timer.repeat <= 0);

    if (restart <= 0) {
        restart = -ev->timer.repeat;
    } else {
        ev->timer.repeat = -restart;
        el_timer_compute_tolerance(ev);
    }
    el_timer_restart_fast(ev, restart);
}

bool el_timer_is_repeated(el_t ev)
{
    CHECK_EV_TYPE(ev, EV_TIMER);

    return ev->timer.repeat > 0;
}

/* }}} */
/* {{{ fd events */

static ALWAYS_INLINE ev_t *el_fd_act_timer_unregister(ev_t *timer)
{
    int pos = qm_del_key(ev, &_G.fd_act, (uint64_t)(uintptr_t)timer);
    ev_t *ev;

    assert (pos >= 0);
    ev = _G.fd_act.values[pos];
    EV_FLAG_RST(ev, FD_WATCHED);
    ev->priv = timer->priv;
    el_timer_unregister(&timer);
    return ev;
}

static ALWAYS_INLINE void el_fd_fire(ev_t *ev, short evs)
{
    const int fd = ev->fd.fd;

    if (EV_IS_TRACED(ev)) {
        e_trace(0, "e-fdv(%p): got event %s%s (%04x)", ev,
                evs & POLLIN ? "IN" : "", evs & POLLOUT ? "OUT" : "", evs);
    }
    if (EV_FLAG_HAS(ev, FD_WATCHED)) {
        ev_t *timer = ev->priv.ptr;

        if (evs & ev->events_act)
            el_timer_restart_fast(timer, -timer->timer.repeat);
        if (EV_FLAG_HAS(ev, IS_BLK)) {
            ev->cb.fd_blk(ev, fd, evs);
        } else {
            (*ev->cb.fd)(ev, fd, evs, timer->priv);
        }
    } else {
        if (EV_FLAG_HAS(ev, IS_BLK)) {
            ev->cb.fd_blk(ev, fd, evs);
        } else {
            (*ev->cb.fd)(ev, fd, evs, ev->priv);
        }
    }
    _G.has_run = true;
}

static void el_act_timer(el_t ev, data_t priv)
{
    el_fd_fire(el_fd_act_timer_unregister(ev), EL_EVENTS_NOACT);
}

static ALWAYS_INLINE ev_t *el_fd_act_timer_register(ev_t *ev, int timeout)
{
    ev_t *timer = el_timer_register_d(timeout, 0, 0, &el_act_timer, ev->priv);

    ev->priv.ptr = el_unref(timer);
    EV_FLAG_SET(ev, FD_WATCHED);
    qm_replace(ev, &_G.fd_act, (uint64_t)(uintptr_t)timer, ev);
    return timer;
}

#ifdef __linux__
#  include "el-epoll.in.c"
#else
#  error one has to port el to your OS
#endif

ev_priority_t (el_fd_set_priority)(ev_t *ev, ev_priority_t priority)
{
    ev_priority_t p = ev->priority;

    if (EV_IS_TRACED(ev)) {
        static lstr_t priority_str[] = {
            [EV_PRIORITY_LOW]    = LSTR_IMMED("LOW"),
            [EV_PRIORITY_NORMAL] = LSTR_IMMED("NORMAL"),
            [EV_PRIORITY_HIGH]   = LSTR_IMMED("HIGH"),
        };

        e_trace(0, "ev-fd(%p): set priority to %*pM", ev,
                LSTR_FMT_ARG(priority_str[priority]));
    }
    CHECK_EV_TYPE(ev, EV_FD);
    ev->priority = priority;
    return p;
}

ev_t *el_fd_register_blk(int fd, bool own_fd, short events, el_fd_b blk,
                         block_t wipe)
{
    return el_blk_register(el_fd_register(fd, own_fd, events, (void *)-1,
                                          NULL),
                           blk, wipe);
}

void el_fd_set_hook(el_t ev, el_fd_f *cb)
{
    CHECK_EV_TYPE(ev, EV_FD);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.fd = cb;
}

short el_fd_get_mask(ev_t *ev)
{
    CHECK_EV_TYPE(ev, EV_FD);
    return ev->events_wanted;
}

int el_fd_get_fd(ev_t *ev)
{
    if (likely(ev)) {
        CHECK_EV_TYPE(ev, EV_FD);
        return ev->fd.fd;
    }
    return -1;
}

void el_fd_mark_fired(ev_t *ev)
{
    CHECK_EV_TYPE(ev, EV_FD);
    if (!EV_FLAG_HAS(ev, FD_FIRED)) {
        ev_add(&_G.fired, ev);
        EV_FLAG_SET(ev, FD_FIRED);
    }
}

int el_fd_watch_activity(el_t ev, short mask, int timeout)
{
    el_t timer;
    int res;

    CHECK_EV_TYPE(ev, EV_FD);

    ev->events_act = mask;
    if (!EV_FLAG_HAS(ev, FD_WATCHED)) {
        if (timeout <= 0)
            return 0;
        el_fd_act_timer_register(ev, timeout);
        return 0;
    }
    timer = ev->priv.ptr;
    res   = -timer->timer.repeat;

    if (timeout == 0) {
        el_fd_act_timer_unregister(timer);
    } else {
        el_timer_restart(timer, timeout);
    }
    return res;
}

int el_fds_loop(ev_t **evs, int count, int timeout, unsigned flags)
{
    struct pollfd pfd[count];
    int res;
    bool has_fired = false;

    for (int i = 0; i < count; i++) {
        ev_t *ev = evs[i];

        if (ev->type == EV_WAKE) {
            ev = ev->wake.read_fd;
        }
        CHECK_EV_TYPE(ev, EV_FD);

        if (EV_FLAG_HAS(ev, FD_FIRED)) {
            EV_FLAG_RST(ev, FD_FIRED);
            dlist_remove(&ev->ev_list);
            el_fd_fire(ev, POLLIN);
            timeout = 0;
            has_fired = true;
        }
        pfd[i] = (struct pollfd){
            .fd = ev->fd.fd,
            .events = ev->events_wanted
        };
    }

    res = poll(pfd, count, timeout);
    if (flags & EV_FDLOOP_HANDLE_TIMERS) {
        if (!qhp_is_empty(timer, &_G.timers)) {
            el_timer_process(get_clock());
        }
    }
    if (flags & EV_FDLOOP_HANDLE_SIGNALS) {
        el_signal_process();
    }
    if (res > 0) {
        for (int i = 0; i < count; i++) {
            ev_t *ev = evs[i];

            if (ev->type == EV_WAKE) {
                ev = ev->wake.read_fd;
            }
            if (pfd[i].revents) {
                el_fd_fire(ev, pfd[i].revents);
                has_fired = true;
            }
        }
    }
    return has_fired ? 1 : 0;
}

int el_fd_loop(ev_t *ev, int timeout, unsigned flags)
{
    return el_fds_loop(&ev, 1, timeout, flags);
}

static void el_fd_process_fired(void)
{
    uint8_t generation;

    if (dlist_is_empty(&_G.fired)) {
        return;
    }

    generation = ev_cache_list(&_G.fired);

    dlist_init(&_G.fired);
    tab_for_each_entry(ev, &_G.cache) {
        EV_FLAG_RST(ev, FD_FIRED);
    }
    tab_for_each_entry(ev, &_G.cache) {
        if (ev->generation != generation) {
            continue;
        }

        CHECK_EV_TYPE(ev, EV_FD);
        el_fd_fire(ev, POLLIN);
    }
}

/* }}} */
/* {{{ proxies events */

ev_t *el_proxy_register_d(el_proxy_f *cb, data_t priv)
{
    return ev_add(&_G.proxy, el_create(EV_PROXY, cb, priv, true));
}

ev_t *el_proxy_register_blk(el_proxy_b blk, block_t wipe)
{
    return el_blk_register(el_proxy_register((void *)-1, NULL), blk, wipe);
}

void el_proxy_set_hook(el_t ev, el_proxy_f *cb)
{
    CHECK_EV_TYPE(ev, EV_PROXY);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    ev->cb.prox = cb;
}

static void el_proxy_change_ready(ev_t *ev, bool was_ready)
{
    dlist_move(was_ready ? &_G.proxy : &_G.proxy_ready, &ev->ev_list);
}

static short el_proxy_set_event_full(ev_t *ev, short evt)
{
    short old = ev->events_avail;

    if (old != evt) {
        bool was_ready = (old & ev->events_wanted) != 0;
        bool is_ready  = (evt & ev->events_wanted) != 0;

        ev->events_avail = evt;
        if (was_ready != is_ready)
            el_proxy_change_ready(ev, was_ready);
    }
    return old;
}

short el_proxy_set_event(ev_t *ev, short mask)
{
    return el_proxy_set_event_full(ev, ev->events_avail | mask);
}

short el_proxy_clr_event(ev_t *ev, short mask)
{
    return el_proxy_set_event_full(ev, ev->events_avail & ~mask);
}

short el_proxy_set_mask(ev_t *ev, short mask)
{
    short old = ev->events_wanted;

    if (old != mask) {
        bool was_ready = (old & ev->events_avail) != 0;
        bool is_ready  = (mask & ev->events_avail) != 0;

        ev->events_wanted = mask;
        if (was_ready != is_ready)
            el_proxy_change_ready(ev, was_ready);
    }
    return old;
}

static void el_loop_proxies(void)
{
    uint8_t generation = ev_cache_list(&_G.proxy_ready);

    tab_for_each_entry(ev, &_G.cache) {
        int avail;

        if (ev->generation != generation) {
            continue;
        }

        CHECK_EV_TYPE(ev, EV_PROXY);
        avail = ev->events_avail;
        if (likely(avail & ev->events_wanted)) {
            if (EV_FLAG_HAS(ev, IS_BLK)) {
                ev->cb.proxy_blk(ev, avail);
            } else {
                (*ev->cb.prox)(ev, avail, ev->priv);
            }
            _G.has_run = true;
        }
    }
}

/* }}} */
/* {{{ el wake events */

static int el_wake_on_event(el_t ev, int fd, short evt, data_t priv)
{
    uint64_t val[16];
    el_t wake = priv.ptr;

    if (wake->wake.use_eventfd) {
        RETHROW(read(fd, val, sizeof(uint64_t)));
    } else {
        while (RETHROW(read(fd, val, sizeof(val))) == sizeof(val));
    }

    if (EV_FLAG_HAS(wake, IS_BLK)) {
        wake->cb.cb_blk(wake);
    } else {
        (*wake->cb.cb)(wake, wake->priv);
    }
    return 0;
}


el_t el_wake_register_d(el_cb_f *cb, data_t priv)
{
    el_t el = el_create(EV_WAKE, cb, priv, true);

    /* Use eventfd if available, since it's much more efficient than
     * the pipe alternative. (Benches show that eventfd wake up the main
     * thread in 7 micro-seconds while a pipe wake up the main thread in
     * 11 micro-seconds)
     */
#ifdef __linux__
    el->wake.write_fd = eventfd(0, O_NONBLOCK | O_CLOEXEC);
#else
    el->wake.write_fd = -1;
#endif

    if (el->wake.write_fd >= 0) {
        el->wake.read_fd = el_fd_register(el->wake.write_fd, true, POLLIN,
                                          &el_wake_on_event, el);
        el->wake.use_eventfd = true;
    } else {
        int fd[2] = { -1, -1 };

        if (pipe(fd) < 0) {
            el_destroy(&el);
            return NULL;
        }

        fd_set_features(fd[0], O_NONBLOCK | O_CLOEXEC);
        fd_set_features(fd[1], O_NONBLOCK | O_CLOEXEC);
        el->wake.write_fd = fd[1];
        el->wake.read_fd = el_fd_register(fd[0], true, POLLIN,
                                          &el_wake_on_event, el);
    }
    el_unref(el->wake.read_fd);
    return el;
}

el_t el_wake_register_blk(el_cb_b blk, block_t wipe)
{
    el_t el = RETHROW_P(el_wake_register((void *)-1, NULL));

    return el_blk_register(el, blk, wipe);
}

static data_t el_wake_unregister(el_t *el)
{
    if (*el) {
        el_fd_unregister(&(*el)->wake.read_fd);
        if (!(*el)->wake.use_eventfd) {
            p_close(&(*el)->wake.write_fd);
        }
        return el_destroy(el);
    }
    return (data_t){ NULL };
}

void el_wake_fire(el_t el)
{
    uint64_t val = 1;

    CHECK_EV_TYPE(el, EV_WAKE);
    IGNORE(write(el->wake.write_fd, &val, sizeof(val)));
}

/* }}} */
/* {{{ fs watch events */

static void el_fs_watch_fire(el_t el, uint32_t event, uint32_t cookie,
                             lstr_t name)
{
    if (EV_FLAG_HAS(el, IS_BLK)) {
        el->cb.fs_watch_blk(el, event, cookie, name);
    } else {
        (*el->cb.fs_watch)(el, event, cookie, name, el->priv);
    }
}

#ifdef __linux__
# include "el-inotify.in.c"
#else
# error one has to port el to your OS
#endif

el_t el_fs_watch_register_blk(const char *path, uint32_t flags,
                              el_fs_watch_b blk, block_t wipe)
{
    el_t el = RETHROW_P(el_fs_watch_register(path, flags, (void *)-1, NULL));

    return el_blk_register(el, blk, wipe);
}

const char *el_fs_watch_get_path(el_t el)
{
    CHECK_EV_TYPE(el, EV_FS_WATCH);
    return el->fs_watch.path;
}

/* }}} */
/* {{{ generic functions */

el_worker_f *el_set_worker(el_worker_f *worker)
{
    SWAP(el_worker_f *, _G.worker, worker);
    return worker;
}

el_worker_f *el_get_worker(void)
{
    return _G.worker;
}

#ifndef NDEBUG
bool el_set_trace(el_t ev, bool trace)
{
    bool res = EV_FLAG_HAS(ev, TRACE);

    if (res == trace)
        return res;

    if (trace) {
        e_trace(0, "el(%p): trace", ev);
        EV_FLAG_SET(ev, TRACE);
    } else {
        e_trace(0, "el(%p): untrace", ev);
        EV_FLAG_RST(ev, TRACE);
    }
    return res;
}
#endif

el_t el_ref(ev_t *ev)
{
    CHECK_EV(ev);
    if (!EV_FLAG_HAS(ev, REFS)) {
        _G.active++;
        EV_FLAG_SET(ev, REFS);
    }
    return ev;
}

el_t el_unref(ev_t *ev)
{
    CHECK_EV(ev);
    ASSERT("unref a FS_WATCH is forbidden", ev->type != EV_FS_WATCH);
    __el_unref(ev);
    return ev;
}

data_t el_set_priv(ev_t *ev, data_t priv)
{
    CHECK_EV(ev);
    assert (!EV_FLAG_HAS(ev, IS_BLK));
    if (ev->type == EV_FD && EV_FLAG_HAS(ev, FD_WATCHED))
        return el_set_priv(ev->priv.ptr, priv);
    SWAP(data_t, ev->priv, priv);
    return priv;
}

void el_loop_timeout(int timeout)
{
    uint64_t clk = get_clock();

    _G.loop_depth++;
    el_timer_process(clk);
    if (unlikely(_G.unloop)) {
        _G.loop_depth--;
        return;
    }
    el_before_process();
    el_idle_process(clk);
    if (!dlist_is_empty(&_G.proxy_ready) || !dlist_is_empty(&_G.idle)
    ||  !dlist_is_empty(&_G.fired))
    {
        timeout = 0;
    }
    if (_G.worker && timeout && !el_has_pending_events()) {
        uint64_t start, end;
        int diff;

        start = get_clock();
        timeout = el_timer_next_expiration(timeout, start);
        _G.worker_running = true;
        _G.worker_end     = start + timeout;
        (*_G.worker)(timeout);
        _G.worker_running = false;;
        end = get_clock();

        diff = end - start;
        if (diff > timeout + 100) {
            e_warning("worker is too long: %dms while expected %dms",
                      diff, timeout);
        } else
        if (diff > MAX(timeout * 2, timeout + 10)) {
            e_trace(0, "worker is too long: %dms while expecting %dms",
                    diff, timeout);
        }
        timeout = MAX(0, timeout - diff);
        clk = end;
    }

    el_fd_process_fired();
    el_loop_fds(el_timer_next_expiration(timeout, clk));
    el_loop_proxies();
    el_signal_process();
    if (_G.loop_depth <= 1) {
        /* To be reentrant we can't reuse unregistered el_t until we came back
         * to the main loop */
        assert (_G.loop_depth == 1);
        dlist_splice(&_G.evs_free, &_G.evs_gc);
    }
    _G.loop_depth--;

    /* Eventually reset the thread-local t_pool. */
    mem_stack_pool_try_reset(&t_pool_g);
}

void el_bl_use(void)
{
    pthread_mutexattr_t attr;

    if (use_big_lock_g)
        e_panic("el bl use has been called twice !");

    use_big_lock_g = true;
    pthread_mutexattr_init(&attr);
    pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
    pthread_mutex_init(&big_lock_g, &attr);
    pthread_mutexattr_destroy(&attr);
    el_bl_lock();
}

void el_bl_lock(void)
{
    if (use_big_lock_g)
        pthread_mutex_lock(&big_lock_g);
}

void el_bl_unlock(void)
{
    if (use_big_lock_g)
        pthread_mutex_unlock(&big_lock_g);
}

void el_cond_wait(pthread_cond_t *cond)
{
    pthread_cond_wait(cond, &big_lock_g);
}

void el_cond_signal(pthread_cond_t *cond)
{
    pthread_cond_signal(cond);
}

void el_loop(void)
{
    while (likely(_G.active) && likely(!_G.unloop)) {
        el_loop_timeout(EL_LOOP_TIMEOUT); /* arbitrary: 59 seconds */
    }
    _G.unloop = false;
}

void el_unloop(void)
{
    _G.unloop = true;
}

bool el_has_pending_events(void)
{
    return el_signal_has_pending_events()
        || el_timer_has_pending_events()
        || el_fds_has_pending_events();
}

bool el_is_terminating(void)
{
    return _G.terminating;
}

data_t el_unregister(ev_t **evp)
{
    data_t res = (data_t)NULL;

    if (*evp) {
        switch ((*evp)->type) {
          case EV_BLOCKER:
          case EV_BEFORE:
          case EV_SIGNAL:
          case EV_PROXY:
          case EV_IDLE:
            return el_destroy(evp);

          case EV_CHILD:    return el_child_unregister(evp);
          case EV_FD:       return el_fd_unregister(evp);
          case EV_TIMER:    return el_timer_unregister(evp);
          case EV_FS_WATCH: return el_fs_watch_unregister(evp);
          case EV_WAKE:     return el_wake_unregister(evp);

          case EV_UNUSED:
            break;
        }
    }

    return res;
}

/* }}} */
/* {{{ el blocking summary dumper */

static void el_for_each(void (^on_ev)(ev_t *))
{
    tab_enumerate(i, bucket, &_G.buckets) {
        int bucket_len = 1 << (i + EV_ALLOC_FACTOR);

        for (int j = 0; j < bucket_len; j++) {
            ev_t *ev = &bucket[j];

            if (ev->type != EV_UNUSED) {
                on_ev(ev);
            }
        }
    }
}

static int el_get_state(sb_t *sb, bool only_blocking)
{
    /* XXX: do not use the t_stack here, since it could be called from
     *      el_shutdown, where the t_stack can be destroyed. */
    int res;
    qv_t(table_hdr) hdr;
    qv_t(table_data) *rows = qv_new(table_data);
    table_hdr_t hdr_data[] = { {
            .title = LSTR_IMMED("EV POINTER"),
        }, {
            .title = LSTR_IMMED("TYPE"),
        }, {
            .title = LSTR_IMMED("CALLBACK"),
        }, {
            .title = LSTR_IMMED("DATA"),
        }, {
            .title = LSTR_IMMED("DETAILS"),
            .omit_if_empty = true,
        }
    };
    uint32_t hdr_size = countof(hdr_data);

    qv_init_static(&hdr, hdr_data, hdr_size);

    el_for_each(^(ev_t *ev) {
        qv_t(lstr) *tab;
        lstr_t details = LSTR_NULL;

        if (only_blocking && !EV_FLAG_HAS(ev, REFS)) {
            return;
        }

        tab = qv_growlen(rows, 1);
        qv_init(tab);
        qv_grow(tab, hdr_size);

        qv_append(tab, lstr_fmt("%p", ev));
        qv_append(tab, LSTR(ev_type_to_str(ev->type)));
        if (ev->flags & EV_FLAG_IS_BLK) {
            qv_append(tab, LSTR("block"));
        } else {
            qv_append(tab, lstr_fmt("%p", (void *)ev->cb.cb));
        }
        qv_append(tab, lstr_fmt("%p", ev->priv.ptr));

        switch (ev->type) {
          case EV_SIGNAL:
            details = lstr_fmt("signal: %d", ev->signo);
            break;
          case EV_CHILD:
            details = lstr_fmt("pid: %d", ev->child.pid);
            break;
          case EV_FD:
            details = lstr_fmt("fd: %d%s, events: %04x",
                               ev->fd.fd,
                               ev->fd.owned ? " (owned)" : "",
                               ev->events_wanted);
            break;
          case EV_TIMER:
            if (ev->timer.repeat < 0) {
                details = lstr_fmt("one shot, expiry: %ju.%03ju, "
                                   "tolerance: %ums",
                                   ev->timer.expiry / 1000,
                                   ev->timer.expiry % 1000,
                                   ev->timer.tolerance);
            } else {
                details = lstr_fmt("repeat: %jdms, next: %ju.%03ju, "
                                   "tolerance: %ums",
                                   ev->timer.repeat,
                                   ev->timer.expiry / 1000,
                                   ev->timer.expiry % 1000,
                                   ev->timer.tolerance);
            }
            break;
          case EV_PROXY:
            details = lstr_fmt("events wanted:%04x, "
                               "events available: %04x",
                               ev->events_wanted, ev->events_avail);
            break;
          default:
            break;
        }
        qv_append(tab, details);
    });

    sb_add_table(sb, &hdr, rows);
    sb_shrink(sb, 1);
    res = rows->len;

    tab_for_each_ptr(tab, rows) {
        qv_deep_wipe(tab, lstr_wipe);
    }
    qv_delete(&rows);

    return res;
}

static void el_print_state(void)
{
    SB_1k(buf);
    int nb_blocking = el_get_state(&buf, true);

    if (nb_blocking) {
        logger_notice(&_G.logger, "el blocking summary:\n%*pM",
                      SB_FMT_ARG(&buf));
    } else {
        logger_notice(&_G.logger, "no blocking event");
    }
}

/* }}} */

/**\}*/
/* Module {{{ */

static void el_on_pwr(el_t evh, int signo, data_t priv)
{
    MODULE_METHOD_RUN_VOID(print_state);
}

static int el_initialize(void *arg)
{
    if (getrlimit(RLIMIT_NOFILE, &fd_limit_g) < 0) {
        e_panic(E_UNIXERR("getrlimit"));
    }
    if (fd_limit_g.rlim_cur < fd_limit_g.rlim_max
    &&  fd_limit_g.rlim_max != RLIM_INFINITY)
    {
        fd_limit_g.rlim_cur = fd_limit_g.rlim_max;
        if (setrlimit(RLIMIT_NOFILE, &fd_limit_g) < 0) {
            e_error(E_UNIXERR("setrlimit"));
        }
    } else
    if (fd_limit_g.rlim_max == RLIM_INFINITY && fd_limit_g.rlim_cur < 8192) {
        fd_limit_g.rlim_cur = 8192;
        if (setrlimit(RLIMIT_NOFILE, &fd_limit_g) < 0) {
            e_error(E_UNIXERR("setrlimit"));
        }
    }

    if (!is_fd_open(STDIN_FILENO)) {
        devnull_dup(STDIN_FILENO);
    }
    if (!is_fd_open(STDOUT_FILENO)) {
        devnull_dup(STDOUT_FILENO);
    }
    if (!is_fd_open(STDERR_FILENO)) {
        dup2(STDOUT_FILENO, STDERR_FILENO);
    }

#if defined(SIGPWR)
    _G.el_on_pwr = el_signal_register(SIGPWR, el_on_pwr, NULL);
#else
    _G.el_on_pwr = el_signal_register(SIGINFO, el_on_pwr, NULL);
#endif

    return 0;
}

static int el_shutdown(void)
{
    el_unregister(&_G.el_on_pwr);
    el_unregister(&_G.el_sigchld_hook);

    /* Wipe all containers in order to remove traces in valgrind, however
     * ensure they remain valid in case some other destructor perform el
     * registrations/unregistrations.
     */
    if (_G.timers.len == 0) {
        qhp_wipe(timer, &_G.timers);
        qhp_init(timer, &_G.timers);
    }
    if (qm_len(ev_assoc, &_G.childs) == 0) {
        qm_wipe(ev_assoc, &_G.childs);
        qm_init(ev_assoc, &_G.childs);
    }
    if (qm_len(ev, &_G.fd_act) == 0) {
        qm_wipe(ev, &_G.fd_act);
        qm_init(ev, &_G.fd_act);
    }
    el_fs_watch_shutdown();

    qv_wipe(&_G.cache);
    qv_init(&_G.cache);

    /* Automatically destroy SIGNAL events (we don't want write boring code to
     * make it ourselves). */
    el_for_each(^(ev_t *ev) {
        if (!EV_FLAG_HAS(ev, REFS) && ev->type == EV_SIGNAL) {
            el_unregister(&ev);
        }
    });

    /* Check for leaked events. */
    if (_G.used) {
        if (logger_is_traced(&_G.logger, 1)) {
            SB_1k(buf);
            int nb_used = el_get_state(&buf, false);

            logger_trace(&_G.logger, 1, "%d events are leaked:\n%*pM",
                         nb_used, SB_FMT_ARG(&buf));
            assert (nb_used == _G.used);
        } else {
            logger_trace(&_G.logger, 0, "%d events are leaked", _G.used);
        }
    } else {
        qv_deep_wipe(&_G.buckets, p_delete);
        qv_init(&_G.buckets);
        _G.evs_alloc_next = _G.evs_alloc_end = NULL;
    }

    return 0;
}

static void el_at_fork_on_child(void)
{
    el_fd_at_fork();
}

static void el_at_fork_on_parent(pid_t pid)
{
    el_child_at_fork_on_parent(pid);
}


MODULE_METHOD(VOID, DEPS_BEFORE, print_state);

_MODULE_ADD_DECLS(el);

__attribute__((constructor))
static void el_module_register(void)
{
    const char *env_home = getenv("HOME");

    log_module_register();

    module_implement(MODULE(el), &el_initialize, &el_shutdown, MODULE(log));
    module_implement_method(MODULE(el), &at_fork_on_child_method,
                            &el_at_fork_on_child);
    module_implement_method(MODULE(el), &at_fork_on_parent_method,
                            &el_at_fork_on_parent);
    module_implement_method(MODULE(el), &print_state_method,
                            &el_print_state);

    /* TODO Fix the fact the module is self-loading then turn it into a
     * standard module declaration. */
    MODULE_REQUIRE(el);

    /* Check that the $HOME environment variable is set. */
    if (!env_home || !*env_home) {
        e_warning("$HOME environment variable is not set, '/' will be used "
                  "as home prefix");
    }
}

/* }}} */
