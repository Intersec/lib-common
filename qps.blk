/***************************************************************************/
/*                                                                         */
/* Copyright 2019 INTERSEC SA                                              */
/*                                                                         */
/* Licensed under the Apache License, Version 2.0 (the "License");         */
/* you may not use this file except in compliance with the License.        */
/* You may obtain a copy of the License at                                 */
/*                                                                         */
/*     http://www.apache.org/licenses/LICENSE-2.0                          */
/*                                                                         */
/* Unless required by applicable law or agreed to in writing, software     */
/* distributed under the License is distributed on an "AS IS" BASIS,       */
/* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.*/
/* See the License for the specific language governing permissions and     */
/* limitations under the License.                                          */
/*                                                                         */
/***************************************************************************/

#include <sys/wait.h>
#include <sys/resource.h>
#include <zlib.h>
#include <lib-common/log.h>
#include <lib-common/datetime.h>
#include <lib-common/unix.h>
#include <lib-common/qlzo.h>
#include <lib-common/el.h>
#include <lib-common/thr.h>
#include "qps.h"
#include "sort.h"
#include "hash.h"

static struct {
    dlist_t qps_head;
    bool    in_snapshot_fork;
    void  (*sighandler)(int, siginfo_t *, void *);

    logger_t logger;
} qps_store_g = {
#define _G  qps_store_g
    .qps_head = DLIST_INIT(_G.qps_head),
    .logger   = LOGGER_INIT_INHERITS(NULL, "qps"),
};

#if 0
#  define TRACE_ALLOC(...)  e_named_trace(4, "qps/"__VA_ARGS__)
#else
#  define TRACE_ALLOC(...)  ((void)0)
#endif

//#define QPS_CHECK_INVARIANTS
#ifdef QPS_CHECK_INVARIANTS
# define QPS_CHECK(expr)         assert(expr)
# define qps_m_check_maps(qps)   __qps_check_maps(qps, true)
#else
# define QPS_CHECK(expr)         ((void)0)
# define qps_m_check_maps(qps)   ((void)0)
#endif

#define CHECK(qps, Expr)  do {                                               \
        if (unlikely(!(Expr))) {                                             \
            if (fatal) {                                                     \
                logger_panic(&qps->logger, #Expr);                           \
            }                                                                \
            return logger_error(&qps->logger, #Expr);                        \
        }                                                                    \
    } while (0)

#if !defined(NDEBUG) && !defined(__has_asan)
# define VG_DO(what, map, pg, n) \
    ({  qps_pg_t _pg = (pg); size_t _n = (n);                                \
        uint8_t *_start = map[_pg & 0xffff].data;                            \
        uint8_t *_end   = _start + _n * QPS_PAGE_SIZE;                       \
        assert (map);                                                        \
        assert (_start);                                                     \
        if (what < 0) {                                                      \
            mem_tool_disallow_memory(_start, _end - _start);                 \
        } else {                                                             \
            mem_tool_allow_memory(_start, _end - _start, what);              \
        }                                                                    \
    })
#define VG_DO_PG(what, qps, pg, n) \
    ({  qps_pg_t __pg = (pg);                                                \
        VG_DO(what, qps->maps.tab[__pg >> 16], __pg, n);                     \
    })
#else
# define VG_DO(...)     ((void)0)
# define VG_DO_PG(...)  ((void)0)
#endif

#define PG_HIDE(qps, pg, n)    VG_DO_PG(-1, qps, pg, n)
#define PG_UNDEF(qps, pg, n)   VG_DO_PG(0, qps, pg, n)
#define PG_DEF(qps, pg, n)     VG_DO_PG(1, qps, pg, n)

#define MAP_HIDE(map, pg, n)    VG_DO(-1, map, pg, n)
#define MAP_UNDEF(map, pg, n)   VG_DO(0, map, pg, n)
#define MAP_DEF(map, pg, n)     VG_DO(1, map, pg, n)


/**
 * \{ \addtogroup qps
 */
/**
 * \section qps_meta QPS Metadata format (v0.1)
 *
 * The \p meta.qps describes the entry points in the QPS store.
 *
 * This file is made of the following items:
 * - 16 octets (qps_meta#sig) of signature (set to #QPS_META_SIG)
 * - 4 octets (qps_meta#generation) for the generation (in the host endianness)
 * - 4 octets (qps_meta#osize) for the original size of the compressed data
 * - 4 octets (qps_meta#csize) for the compressed data size
 * - 4 octets (qps_meta#psize) for the private data size
 * - 4 octets (qps_meta#pcsize) for the private data compressed size
 * - qps_meta#csize octets of LZO compressed data
 * - qps_meta#pcsize octets of LZO compressed private data
 * - 20 octets made of the sha1 signature of the rest of the file.
 *
 * The compressed data is structured like this:
 * - 4 octets to hold the current head of the handles freelist (see
 *   qps_t#handles_freelist)
 *
 * - 4 octets to hold the first unallocated handle (see qps_t#handles_max)
 *
 * - follows \p DIV_ROUND_UP(handles_max, QPS_HANDLE_COUNT) words of 4 octets
 *   listing pages pointers (as #qps_pg_t) inside the QPS holding the actual
 *   data pointers corresponding to the qps_t#handles_max handles.
 *
 * - 4 octets of number of 2-words big records describing the state of the
 *   paged allocator.
 *
 * A paged allocator state descriptor is made of two words. Depending on the
 * bits set in the first word the record meaning changes:
 * - if #QPS_META_MAP_TLSF is set, then the record says that the record
 *   describes a TLSF-allocator map. The lower 16 bits of the first word hold
 *   the map id (\p mapno). The second word contains the amount of data
 *   allocated in that map when the snapshot was taken (see
 *   qps_map_t#remaining).
 *
 * - if #QPS_META_MAP_PAGED is set, then the record describes a
 *   paged-allocator map. The second word must be zero.
 */
/** \} */

/**
 * \{ \addtogroup qps
 */
/* {{{ */

/*
 * used in both pg and memory hdrs
 */
#define QPS_BLK_FREE       2
#define QPS_BLK_USED       0
#define QPS_BLK_PREV_FREE  1
#define QPS_BLK_PREV_USED  0

struct qps_pghdr_t {
    uint16_t flags;
    uint16_t size;
    union {
        struct {
            uint32_t handle;
            uint32_t blk_prev;
        };
        struct {
            qps_pg_t next;
            qps_pg_t prev;
        } free;
    };
};

#define QPS_MBLK_HDRSZ    offsetof(qps_mhdr_t, data)
struct qps_mhdr_t {
#if QPS_USE_REDZONES
    uint64_t rz_after_block;
    uint64_t rz_alloc_size;
#endif
    uint32_t flags;
    uint32_t handle;
#if QPS_USE_REDZONES
    uint64_t rz_before_block;
#endif

    union {
        struct {
            qps_mhdr_t **prev_next;
            qps_mhdr_t  *next;
        } free;
        void   *padding[3];
        uint8_t data[0];
    };
};

static ALWAYS_INLINE qps_ptr_t qps_encode(const void *ptr)
{
    return (qps_ptr_t){
        .pgno = qps_pg_of(ptr),
        .addr = cast(uintptr_t, ptr) & QPS_PAGE_MASK,
    };
}

/* }}} */
/** @{ \name Internal: paged allocator helpers */
/* {{{ */

/*
 * N = QPS_PGL2_LEVELS
 *
 * l1
 * v
 * k:   2^kN  2^k(N+1)  ...  2^k(N + N - 1)
 * 2:   2N    2(N+1)    ...  2(N + N - 1)
 * 1:   1N    1(N+1)    ...  1(N + N - 1)
 * 0:   0     1         ...  N - 1
 */

static ALWAYS_INLINE size_t qps_pg_l12_size_(uint32_t l1, uint32_t l2)
{
    if (l1 == 0)
        return l2;
    return (QPS_PGL2_LEVELS + l2) << (l1 - 1);
}

static __unused__ ALWAYS_INLINE
size_t qps_pg_l12_minsize(uint32_t l1, uint32_t l2)
{
    assert (l2 < QPS_PGL2_LEVELS);
    return qps_pg_l12_size_(l1, l2);
}

static __unused__ ALWAYS_INLINE
size_t qps_pg_l12_maxsize(uint32_t l1, uint32_t l2)
{
    assert (l2 < QPS_PGL2_LEVELS);
    return qps_pg_l12_size_(l1, l2 + 1);
}

static void qps_pg_alloc_search(uint32_t n0, uint32_t *l1, uint32_t *l2)
{
    uint32_t n = n0;
    QPS_CHECK(n < (1U << (QPS_PGL1_LEVELS + QPS_PGL2_SHIFT)));

    if (likely(n < QPS_PGL2_LEVELS)) {
        *l1 = 0;
        *l2 = n;
    } else {
        n  += BITMASK_LT(uint32_t, bsr32(n) - QPS_PGL2_SHIFT);
        *l1 = bsr32(n) - QPS_PGL2_SHIFT + 1;
        *l2 = (n >> (*l1 - 1)) - QPS_PGL2_LEVELS;
    }
    QPS_CHECK(n0 <= qps_pg_l12_minsize(*l1, *l2));
}

static void qps_pg_insert_search(uint32_t n, uint32_t *l1, uint32_t *l2)
{
    QPS_CHECK(n < (1U << (QPS_PGL1_LEVELS + QPS_PGL2_SHIFT)));

    if (likely(n < QPS_PGL2_LEVELS)) {
        *l1 = 0;
        *l2 = n;
    } else {
        *l1 = bsr32(n) - QPS_PGL2_SHIFT + 1;
        *l2 = (n >> (*l1 - 1)) - QPS_PGL2_LEVELS;
    }
    QPS_CHECK(n >= qps_pg_l12_minsize(*l1, *l2));
    QPS_CHECK(n <  qps_pg_l12_maxsize(*l1, *l2));
}

static qps_pg_t
qps_pg_find_blk(qps_t *qps, uint32_t n, uint32_t *l1, uint32_t *l2)
{
    uint32_t tmp = qps->pgs.l2_bitmap[*l1] & BITMASK_GE(uint32_t, *l2);

    if (tmp) {
        *l2 = bsf32(tmp);
        QPS_CHECK(n <= qps_pg_l12_minsize(*l1, *l2));
        return qps->pgs.blks[*l1][*l2];
    }
    tmp = qps->pgs.l1_bitmap & BITMASK_GT(uint32_t, *l1);
    if (likely(tmp)) {
        *l1 = bsf32(tmp);
        *l2 = bsf32(qps->pgs.l2_bitmap[*l1]);
        QPS_CHECK(n <= qps_pg_l12_minsize(*l1, *l2));
        return qps->pgs.blks[*l1][*l2];
    }
    return QPS_PG_NULL;
}

static void qps_pg_blk_insert(qps_t *qps, qps_pg_t blk, size_t n)
{
    qps_pghdr_t *hdr = qps->hdrs + blk;
    uint32_t l1, l2;

    qps_pg_insert_search(n, &l1, &l2);
    hdr->flags = QPS_BLK_PREV_USED | QPS_BLK_FREE;
    hdr->size  = n;
    if ((hdr->free.next = qps->pgs.blks[l1][l2])) {
        qps->hdrs[hdr->free.next].free.prev = blk;
    } else {
        SET_BIT(&qps->pgs.l1_bitmap, l1);
        SET_BIT(qps->pgs.l2_bitmap + l1, l2);
    }
    qps->pgs.blks[l1][l2] = blk;
    hdr->free.prev = 0;

    hdr[n].flags   |= QPS_BLK_PREV_FREE;
    hdr[n].blk_prev = blk;
}

static size_t qps_pg_blk_remove(qps_t *qps, qps_pg_t blk)
{
    uint32_t l1, l2;
    qps_pghdr_t *hdr = qps->hdrs + blk;

    qps_pg_insert_search(hdr->size, &l1, &l2);
    if (hdr->free.prev) {
        qps->hdrs[hdr->free.prev].free.next = hdr->free.next;
    } else {
        qps->pgs.blks[l1][l2] = hdr->free.next;
    }
    if (hdr->free.next) {
        qps->hdrs[hdr->free.next].free.prev = hdr->free.prev;
    } else
    if (hdr->free.prev == 0) {
        RST_BIT(qps->pgs.l2_bitmap + l1, l2);
        if (!qps->pgs.l2_bitmap[l1])
            RST_BIT(&qps->pgs.l1_bitmap, l1);
    }

    return hdr->size;
}

static int qps_pg_check_hdrs_aux(qps_t *qps, qps_pg_t blk, bool fatal)
{
    qps_pghdr_t *hdrs = qps->hdrs + (blk & 0xffff0000);

    CHECK(qps, !(hdrs[0].flags & QPS_BLK_FREE));
    CHECK(qps, hdrs[0].size == 1);

    for (uint32_t pg = 1; pg < QPS_MAP_PAGES; ) {
        uint32_t sz = hdrs[pg].size;

        CHECK(qps, sz >= 1 && pg + sz <= QPS_MAP_PAGES);
        if (hdrs[pg].flags & QPS_BLK_FREE) {
            CHECK(qps, hdrs[pg + sz].flags & QPS_BLK_PREV_FREE);
            CHECK(qps, !(hdrs[pg + sz].flags & QPS_BLK_FREE));
        } else {
            CHECK(qps, !(hdrs[pg + sz].flags & QPS_BLK_PREV_FREE));
        }
        pg += sz;
    }

    CHECK(qps, !(hdrs[QPS_MAP_PAGES].flags & QPS_BLK_FREE));
    CHECK(qps, hdrs[QPS_MAP_PAGES].size == 1);
    return 0;
}

static void qps_pg_check_hdrs(qps_t *qps)
{
#ifdef QPS_CHECK_INVARIANTS
    for (int i = 0; i < qps->maps.len; i++) {
        qps_map_t *map = qps->maps.tab[i];

        if (map && qps_map_is_pg(map))
            qps_pg_check_hdrs_aux(qps, i << 16, true);
    }
#endif
}

/* }}} */
/** @} */
/** @{ \name Internal: tlsf allocator helpers */
/* {{{ */

/*
 * N = QPS_ML2_LEVELS
 * S = (1 << QPS_ML2_OFFSET)
 *
 * l1
 * v
 * k:   2^kSN  2^kS(N+1)  ...  2^kS(N + N - 1)
 * 2:   2SN    2S(N+1)    ...  2S(N + N - 1)
 * 1:   1SN    1S(N+1)    ...  1S(N + N - 1)
 * 0:   0      S          ...  S(N - 1)
 */

static ALWAYS_INLINE size_t qps_m_l12_size_(uint32_t l1, uint32_t l2)
{
    if (l1 == 0)
        return l2 << QPS_ML2_OFFSET;
    return (QPS_ML2_LEVELS + l2) << (l1 - 1 + QPS_ML2_OFFSET);
}

static __unused__ ALWAYS_INLINE
size_t qps_m_l12_minsize(uint32_t l1, uint32_t l2)
{
    assert (l2 < QPS_ML2_LEVELS);
    return qps_m_l12_size_(l1, l2);
}

static __unused__ ALWAYS_INLINE
size_t qps_m_l12_maxsize(uint32_t l1, uint32_t l2)
{
    assert (l2 < QPS_ML2_LEVELS);
    return qps_m_l12_size_(l1, l2 + 1);
}

static size_t qps_m_alloc_search(size_t sz, uint32_t *l1, uint32_t *l2)
{
    static size_t const offs = QPS_ML2_SHIFT + QPS_ML2_OFFSET;
    size_t size = sz;

    if (size < (1U << offs)) {
        *l1 = 0;
        *l2 = size >> QPS_ML2_OFFSET;
    } else {
        uint32_t t = BITMASK_LT(uint32_t, bsr32(size) - QPS_ML2_SHIFT);
        size_t bits;

        size += t;
        bits = bsr32(size) + 1;
        *l1  = bits - offs;
        *l2  = (size >> (bits - QPS_ML2_SHIFT - 1)) - QPS_ML2_LEVELS;
        size &= ~t;
    }
    QPS_CHECK(sz <= size);
    QPS_CHECK(size <= qps_m_l12_minsize(*l1, *l2));
    return size;
}

static void qps_m_insert_search(size_t size, uint32_t *l1, uint32_t *l2)
{
    static size_t const offs = QPS_ML2_SHIFT + QPS_ML2_OFFSET;

    if (size < (1U << offs)) {
        *l1 = 0;
        *l2 = size >> QPS_ML2_OFFSET;
    } else {
        size_t bits = bsr32(size) + 1;

        *l1  = bits - offs;
        *l2  = (size >> (bits - QPS_ML2_SHIFT - 1)) - QPS_ML2_LEVELS;
    }
    QPS_CHECK(size >= qps_m_l12_minsize(*l1, *l2));
    QPS_CHECK(size < qps_m_l12_maxsize(*l1, *l2));
}

static qps_mhdr_t *
qps_m_find_blk(qps_t *qps, size_t size, uint32_t *l1, uint32_t *l2)
{
    uint32_t tmp = qps->m.l2_bitmap[*l1] & ((unsigned)-1 << *l2);

    if (tmp) {
        *l2 = bsf32(tmp);
        QPS_CHECK(size <= qps_m_l12_minsize(*l1, *l2));
        return qps->m.blks[*l1][*l2];
    }
    tmp = qps->m.l1_bitmap & BITMASK_GT(uint32_t, *l1);
    if (likely(tmp)) {
        *l1 = bsf32(tmp);
        *l2 = bsf32(qps->m.l2_bitmap[*l1]);
        QPS_CHECK(size <= qps_m_l12_minsize(*l1, *l2));
        return qps->m.blks[*l1][*l2];
    }
    return NULL;
}

static qps_mhdr_t *qps_m_blk_next(qps_mhdr_t *blk, size_t n)
{
    return acast(qps_mhdr_t, blk->data + n);
}

static qps_mhdr_t *qps_m_blk_get_prev(qps_mhdr_t *blk)
{
    return ((qps_mhdr_t **)blk)[-1];
}

static void qps_m_blk_set_prev_free(qps_mhdr_t *blk, qps_mhdr_t *prev)
{
    qps_mhdr_t **ptr = (qps_mhdr_t **)blk - 1;

    blk->flags |= QPS_BLK_PREV_FREE;
#if QPS_USE_REDZONES
    mem_tool_allow_memory(ptr, sizeof(qps_mhdr_t *), false);
#endif
    *ptr = prev;
}

static size_t qps_m_blk_size(const qps_mhdr_t *blk)
{
    return blk->flags & ~3;
}

static void qps_m_blk_insert(qps_t *qps, qps_mhdr_t *blk, size_t n)
{
    uint32_t l1, l2;

#if QPS_USE_REDZONES
    mem_tool_allow_memory(blk, sizeof(qps_mhdr_t), false);
#endif
    blk->flags = n | QPS_BLK_PREV_USED | QPS_BLK_FREE;
    qps_m_insert_search(n, &l1, &l2);
    if ((blk->free.next = qps->m.blks[l1][l2])) {
        blk->free.next->free.prev_next = &blk->free.next;
    } else {
        SET_BIT(&qps->m.l1_bitmap, l1);
        SET_BIT(qps->m.l2_bitmap + l1, l2);
    }
    qps->m.blks[l1][l2] = blk;
    blk->free.prev_next = &qps->m.blks[l1][l2];

    qps_m_blk_set_prev_free(qps_m_blk_next(blk, n), blk);
}

static size_t qps_m_blk_remove(qps_t *qps, qps_mhdr_t *blk)
{
    uint32_t l1, l2;
    size_t bsz = qps_m_blk_size(blk);

    qps_m_insert_search(bsz, &l1, &l2);
    *blk->free.prev_next = blk->free.next;
    if (blk->free.next) {
        blk->free.next->free.prev_next = blk->free.prev_next;
    } else
    if (blk->free.prev_next == &qps->m.blks[l1][l2]) {
        RST_BIT(qps->m.l2_bitmap + l1, l2);
        if (!qps->m.l2_bitmap[l1])
            RST_BIT(&qps->m.l1_bitmap, l1);
    }

#if QPS_USE_REDZONES
    mem_tool_disallow_memory(blk, sizeof(qps_mhdr_t));
#endif
    return bsz;
}

static void qps_m_register_map(qps_t *qps, qps_map_t *map)
{
    void *map_end = &map[QPS_MAP_PAGES];
    qps_mhdr_t *g_blk, *f_blk, *e_blk; /* guard, free, end */

    g_blk = (qps_mhdr_t *)&map[1];
    g_blk->flags = QPS_MBLK_HDRSZ | QPS_BLK_PREV_USED | QPS_BLK_USED;

    f_blk = qps_m_blk_next(g_blk, QPS_MBLK_HDRSZ);

    e_blk = container_of(map_end, qps_mhdr_t, data);
    e_blk->flags = 0 | QPS_BLK_USED;

    qps_m_blk_insert(qps, f_blk, (uint8_t *)e_blk - f_blk->data);
}

static void qps_m_malloclike_map(qps_t *qps, qps_map_t *map)
{
#if QPS_USE_REDZONES
    void       *map_end = &map[QPS_MAP_PAGES];
    qps_mhdr_t *blk     = (qps_mhdr_t *)&map[1];
    qps_mhdr_t *blk_end = container_of(map_end, qps_mhdr_t, data);

    blk = qps_m_blk_next(blk, QPS_MBLK_HDRSZ);
    if (qps_is_ro(qps, map)) {
        while (blk < blk_end) {
            size_t      bsz = qps_m_blk_size(blk);
            qps_mhdr_t *nxt = qps_m_blk_next(blk, bsz);
            qps_ptr_t  *hptr, bptr;
            void       *ptr;

            if (bsz && !(blk->flags & QPS_BLK_FREE)) {
                hptr = qps_handle_slot(qps, blk->handle);
                bptr = qps_encode(blk->data);
                if (hptr->pgno == bptr.pgno && hptr->addr == bptr.addr) {
                    ptr = (uint8_t *)qps_pg_deref(qps, hptr->pgno) + hptr->addr;
                    mem_tool_malloclike(ptr, blk->rz_alloc_size, 8, false);
                    mem_tool_allow_memory(ptr, blk->rz_alloc_size, true);
                }
            }
            blk = nxt;
        }
    } else {
        while (blk < blk_end) {
            size_t      bsz = qps_m_blk_size(blk);
            qps_mhdr_t *nxt = qps_m_blk_next(blk, bsz);

            if (bsz && !(blk->flags & QPS_BLK_FREE)) {
                assert (blk->rz_alloc_size <= bsz);
                mem_tool_malloclike(blk->data, blk->rz_alloc_size, 8, false);
                logger_info(&qps->logger, "malloclike(h:%d, sz:%zd)",
                            blk->handle, bsz);
                mem_tool_allow_memory(blk->data, blk->rz_alloc_size, true);
            }
            blk = nxt;
        }
    }
#endif
}

static int qps_m_check_map(qps_t *qps, qps_map_t *map, bool fatal)
{
    void       *map_end = &map[QPS_MAP_PAGES];
    qps_mhdr_t *blk     = (qps_mhdr_t *)&map[1];
    qps_mhdr_t *blk_end = container_of(map_end, qps_mhdr_t, data);
    size_t allocated = 0;

    CHECK(qps,
          blk->flags == (QPS_MBLK_HDRSZ | QPS_BLK_PREV_USED | QPS_BLK_USED));
    CHECK(qps, (blk_end->flags | QPS_BLK_PREV_FREE) == QPS_BLK_PREV_FREE);

    blk = qps_m_blk_next(blk, QPS_MBLK_HDRSZ);
    if (qps_is_ro(qps, map)) {
        while (blk < blk_end) {
            size_t      bsz = qps_m_blk_size(blk);
            qps_mhdr_t *nxt = qps_m_blk_next(blk, bsz);
            qps_ptr_t  *hptr, bptr;

            CHECK(qps, qps_m_blk_next(blk, bsz) <= blk_end);
            if (blk->flags & QPS_BLK_FREE) {
                CHECK(qps, nxt->flags & QPS_BLK_PREV_FREE);
                CHECK(qps, !(nxt->flags & QPS_BLK_FREE));
            } else {
                CHECK(qps, !(nxt->flags & QPS_BLK_PREV_FREE));
                CHECK(qps, blk->handle);
                hptr = qps_handle_slot(qps, blk->handle);
                bptr = qps_encode(blk->data);
                if (hptr->pgno == bptr.pgno && hptr->addr == bptr.addr)
                    allocated += QPS_MBLK_HDRSZ + bsz;
            }
            blk = nxt;
        }
        if (map->hdr.remaining != allocated) {
            if (fatal) {
                logger_panic(&qps->logger, "RO map [%x] remaining disparity: "
                             "delta is %zd", map->hdr.mapno,
                             map->hdr.remaining - allocated);
            } else {
                return logger_error(&qps->logger, "RO map [%x] remaining "
                                    "disparity: delta is %zd",
                                    map->hdr.mapno,
                                    map->hdr.remaining - allocated);
            }
        }
    } else {
        while (blk < blk_end) {
            size_t      bsz = qps_m_blk_size(blk);
            qps_mhdr_t *nxt = qps_m_blk_next(blk, bsz);

            CHECK(qps, qps_m_blk_next(blk, bsz) <= blk_end);
            if (blk->flags & QPS_BLK_FREE) {
                CHECK(qps, nxt->flags & QPS_BLK_PREV_FREE);
                CHECK(qps, !(nxt->flags & QPS_BLK_FREE));
            } else {
                CHECK(qps, !(nxt->flags & QPS_BLK_PREV_FREE));
                CHECK(qps, blk->handle);
                allocated += QPS_MBLK_HDRSZ + bsz;
            }
            blk = nxt;
        }
        if (map->hdr.allocated != allocated) {
            if (fatal) {
                logger_panic(&qps->logger, "RW map [%x] allocated disparity: "
                             "delta is %zd", map->hdr.mapno,
                             map->hdr.allocated - allocated);
            } else {
                return logger_error(&qps->logger, "RW map [%x] allocated "
                                    "disparity: delta is %zd", map->hdr.mapno,
                                    map->hdr.allocated - allocated);
            }
        }
    }
    return 0;
}

int __qps_check_maps(qps_t *qps, bool fatal)
{
    for (int i = 0; i < qps->maps.len; i++) {
        qps_map_t *map = qps->maps.tab[i];

        if (!map || map->hdr.generation == 0)
            continue;
        if (qps_map_is_pg(map)) {
            RETHROW(qps_pg_check_hdrs_aux(qps, i << 16, fatal));
        } else {
            RETHROW(qps_m_check_map(qps, map, fatal));
        }
    }
    return 0;
}


/* }}} */
/** @} */
/** @{ \name Internal: file-backed store helpers */
/* {{{ */

static int qps_open_temp(qps_t *qps, const char *path)
{
    logger_trace(&qps->logger, 1, "unlinkat(%s)", path);
    if (unlinkat(qps->dfd, path, 0) < 0) {
        if (errno != ENOENT)
            qps_enospc(qps, "unlinkat");
    }
    logger_trace(&qps->logger, 1, "openat(%s)", path);
    return x_openat(qps->dfd, path, O_RDWR | O_CREAT | O_EXCL, 0444);
}

static int qps_smaps_find(qv_t(qpsm) const *tab, const void *addr, bool wantit)
{
    const qps_map_t *map = qps_map_of(addr);
    size_t l = 0, r = tab->len;

    while (l < r) {
        size_t i = (l + r) / 2;

        if (tab->tab[i] == map)
            return i;
        if (tab->tab[i] < map) {
            l = i + 1;
        } else {
            r = i;
        }
    }
    if (wantit)
        return -1;
    return l;
}

static void
qps_map_recycle(qps_t *qps, qps_map_t *map, uint16_t no, bool quarantine)
{
    int pos;

    logger_trace(&qps->tracing_logger, 1, "map %x recycled", map->hdr.mapno);

    /* remove it from the allowed maps */
    qps->maps.tab[no] = NULL;
    pos = qps_smaps_find(&qps->smaps, map, true);
    if (pos >= 0)
        qv_remove(&qps->smaps, pos);
    qv_append(&qps->omaps, map);

    /* quarantine the map id until the next snapshot */
    if (quarantine) {
        qv_append(&qps->no_blocked, no);
    } else {
        pos = bisect32(no, qps->no_free.tab, qps->no_free.len, NULL);

        assert (pos == qps->no_free.len || qps->no_free.tab[pos] != no);
        qv_insert(&qps->no_free, pos, no);
    }

    /* keep the address around */
    x_mmap(map, QPS_MAP_SIZE, PROT_NONE,
           MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
}

static void qps_unquarantine_nos(qps_t *qps)
{
    char buf[32];

    qv_splice(&qps->no_free, qps->no_free.len, 0,
              qps->no_blocked.tab, qps->no_blocked.len);
    dsort32(qps->no_free.tab, qps->no_free.len);

    for (int i = 0; i < qps->no_blocked.len; i++) {
         /* remove the potential file on disk */
         snprintf(buf, sizeof(buf), "%08x.qps", qps->no_blocked.tab[i]);
         logger_trace(&qps->logger, 1, "unlinkat(%s)", buf);
         unlinkat(qps->dfd, buf, 0);
    }
    qv_clear(&qps->no_blocked);
}

/** Maps a file of size QPS_MAP_SIZE.
 *
 * This function maps a file of QPS_MAP_SIZE octets at an address aligned to
 * QPS_MAP_SIZE.
 *
 * \param[in] qps   the qps
 * \param[in] fd    the file descriptor to map.
 * \param[in] at    if not NULL, position at which the map must be mapped.
 * \return  \p NULL if the map failed, the address of the map else.
 */
static void *qps_map_fd(qps_t *qps, int fd, void *at)
{
    const uintptr_t sz = QPS_MAP_SIZE;
    int prot;
    void *where;
    int flags;

    if (fd < 0) {
        flags = MAP_PRIVATE | MAP_FIXED | MAP_ANONYMOUS;
        prot  = PROT_READ | PROT_WRITE;
    } else {
        flags = MAP_SHARED  | MAP_FIXED;
        prot  = PROT_READ;
    }

    if (at) {
        where = at;
    } else
    if (qps->omaps.len) {
        where = *tab_last(&qps->omaps);
        qv_shrink(&qps->omaps, 1);
    } else {
        uint8_t *map, *fix;

        map = x_mmap(NULL, 2 * sz, prot, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
        fix = (uint8_t *)ROUND_UP((uintptr_t)map, sz);
        if (fix != map)
            x_munmap(map, fix - map);
        if (fix + sz != map + 2 * sz)
            x_munmap(fix + sz, map + sz - fix);
        where = fix;
    }
    assert (((uintptr_t)where & QPS_MAP_MASK) == 0);

    x_mmap(where, sz, prot, flags, fd, 0);
    madvise(where, QPS_MAP_SIZE, MADV_RANDOM);
    return where;
}

/** \brief Grow \a qps->hdrs.
 *
 * This function grows \a qps->hdrs enough so that a map of id \a no can be
 * described in them.
 */
static void qps_alloc_hdrs(qps_t *qps, int olen, int no)
{
    const size_t o = QPS_MAP_PAGES * olen;
    const size_t n = QPS_MAP_PAGES * (no + 1);

    if (no >= qps->maps.len) {
        int extra = no + 1 - qps->maps.len;
        p_clear(qv_growlen(&qps->maps, extra), extra);
    }
    if (olen <= no) {
        p_realloc0(&qps->hdrs, o + 1, n + 1);
        for (size_t i = o; i <= n; i += QPS_MAP_PAGES) {
            qps->hdrs[i].flags |= QPS_BLK_USED;
            qps->hdrs[i].size   = 1;
        }
    } else {
        p_clear(qps->hdrs + QPS_MAP_PAGES * no + 1, QPS_MAP_PAGES - 1);
    }
}

/** Call mprotect() on a given map. */
static void qps_map_protect(const qps_t *nullable qps, qps_map_t *map,
                            int prot)
{
    if (prot & PROT_WRITE) {
        logger_trace(qps ? &qps->logger : &_G.logger, 1, "unprotect %p:%d",
                     map->hdr.qps, map->hdr.mapno);
    } else {
        logger_trace(qps ? &qps->logger : &_G.logger, 1, "protect %p:%d",
                     map->hdr.qps, map->hdr.mapno);
    }
    mprotect(map + 1, QPS_MAP_SIZE - QPS_PAGE_SIZE, prot);
}

static uint32_t qps_map_find_no(qps_t *qps)
{
    int no = qps->maps.len;

    if (qps->no_free.len) {
        no = *tab_last(&qps->no_free);
        qv_shrink(&qps->no_free, 1);
    }

    qps_alloc_hdrs(qps, qps->maps.len, no);
    return no;
}

static qps_map_t *qps_map_create_raw(qps_t *qps, uint32_t no, const char *sig)
{
    qps_map_t *map;

    map = qps_map_fd(qps, -1, NULL);
    map->hdr.mapno      = no;
    map->hdr.qps        = qps;
    map->hdr.generation = qps->generation;
    memcpy(map->hdr.sig, sig, sizeof(map->hdr.sig));
    return map;
}
#define qps_map_m_create_raw(qps, no)  \
    qps_map_create_raw((qps), (no), QPS_MAP_MEM_SIG)
#define qps_map_pg_create_raw(qps, no)  \
    qps_map_create_raw((qps), (no), QPS_MAP_PG_SIG)

static void qps_map_bless(qps_t *qps, qps_map_t *map)
{
    qps->maps.tab[map->hdr.mapno] = map;
    qv_insert(&qps->smaps, qps_smaps_find(&qps->smaps, map, false), map);
}

/** QPS map creation helper.
 *
 * This function finds a free map slot (trying to reuse an old file when
 * possible).
 *
 * Then it setups it so that it's ready for use either as a paged-allocator or
 * a tlsf-allocator map.
 *
 * \param[in]  qps     the qps object
 * \param[in]  for_pg
 *   whether the created page should be used for the paged-allocator
 *   (\p true) or for the tlsf one (\p false).
 * \return
 *   - -1 on error
 *   - 0 on success
 */
static void qps_map_create(qps_t *qps, bool for_pg)
{
    uint32_t no = qps_map_find_no(qps);
    qps_map_t *map;

    if (for_pg) {
        map = qps_map_pg_create_raw(qps, no);
    } else {
        map = qps_map_m_create_raw(qps, no);
    }
    qps_map_bless(qps, map);

    if (for_pg) {
        PG_DEF(qps, (no << 16), 1);
        PG_HIDE(qps, (no << 16) + 1, QPS_MAP_PAGES - 1);
        qps_pg_blk_insert(qps, (no << 16) + 1, QPS_MAP_PAGES - 1);
        qps_pg_check_hdrs(qps);
        qps_map_protect(qps, map, PROT_READ);
    } else {
        qps_m_register_map(qps, map);
    }
    logger_trace(&qps->logger, 1, "qps_map_create(%p) = %d[%s]",
                 qps, no, for_pg ? "pg" : "mem");
}

static bool qps_map_pg_is_all_free(const qps_t *qps, const qps_map_t *map)
{
    qps_pghdr_t *hdrs = qps->hdrs + map->hdr.mapno * QPS_MAP_PAGES;

    return (hdrs[1].flags & QPS_BLK_FREE)
        && hdrs[1].size == QPS_MAP_PAGES - 1;
}

static void qps_map_pg_snapshot(qps_t *qps, qps_map_t *map, uint32_t gen)
{
    qps_pghdr_t *hdrs = qps->hdrs + map->hdr.mapno * QPS_MAP_PAGES;
    char buf[32], dst[32];
    gzFile out;
    int  fd;

    assert (qps_map_is_pg(map));
    snprintf(dst, sizeof(dst), "%08x.%08x.qpz", map->hdr.mapno, gen);
    snprintf(buf, sizeof(buf), "%08x.%08x.qpt", map->hdr.mapno, gen);
    fd = qps_open_temp(qps, buf);
    out = gzdopen(dup(fd), "wb2");
    if (!out) {
        qps_enospc(qps, "gzdopen");
    }

#if ZLIB_VERNUM >= 0x1240
    gzbuffer(out, 1 << 20);
#endif
    if (gzwrite(out, &map->hdr, sizeof(qps_map_t)) != sizeof(qps_map_t)) {
        qps_enospc(qps, "gzwrite");
    }

    for (uint32_t pg = 1; pg < QPS_MAP_PAGES; pg += hdrs[pg].size) {
        uint32_t tmp[2] = {
            hdrs[pg].size,
            hdrs[pg].handle,
        };

        assert (tmp[0] >= 1 && pg + tmp[0] <= QPS_MAP_PAGES);
        if (hdrs[pg].flags & QPS_BLK_FREE) {
            tmp[0] |= 1 << 16;
            if (gzwrite(out, tmp, sizeof(tmp)) != sizeof(tmp)) {
                qps_enospc(qps, "gzwrite");
            }
        } else {
            int sz = tmp[0] * QPS_PAGE_SIZE;

            if (gzwrite(out, tmp, sizeof(tmp)) != sizeof(tmp)) {
                qps_enospc(qps, "gzwrite");
            }
            if (gzwrite(out, map + pg, sz) != sz) {
                qps_enospc(qps, "gzwrite");
            }
        }
    }

    if (gzclose(out)) {
        logger_trace(&qps->logger, 1, "unlinkat(%s)", buf);
        unlinkat(qps->dfd, buf, 0);
        close(fd);
        qps_enospc(qps, "gzclose");
    }

    x_fdatasync(fd);
    x_close(fd);
    x_renameat(qps->dfd, buf, qps->dfd, dst);
}

static void qps_map_m_snapshot(qps_t *qps, qps_map_t *map, uint32_t gen)
{
    char buf[32], dst[32];
    int  fd;
    void       *map_end = &map[QPS_MAP_PAGES];
    qps_mhdr_t *prev    = (qps_mhdr_t *)&map[0];
    qps_mhdr_t *blk     = (qps_mhdr_t *)&map[1];
    qps_mhdr_t *blk_end = container_of(map_end, qps_mhdr_t, data);

    snprintf(buf, sizeof(buf), "%08x.qpt", map->hdr.mapno);
    snprintf(dst, sizeof(dst), "%08x.qps", map->hdr.mapno);
    fd = qps_open_temp(qps, buf);
    x_ftruncate(fd, QPS_MAP_SIZE);

    while (blk <= blk_end) {
        size_t bsz       = qps_m_blk_size(blk);
        qps_mhdr_t *next = qps_m_blk_next(blk, bsz);

        if (blk->flags & QPS_BLK_FREE) {
            bsz = 0;
        }

        if (next > blk_end
        ||  (byte *)next - (byte *)blk - QPS_MBLK_HDRSZ - bsz >= 4096)
        {
            x_pwrite(fd, prev, (byte *)blk - (byte *)prev + QPS_MBLK_HDRSZ + bsz,
                     (byte *)prev - (byte *)map);
            prev = next;
        }

        blk = next;
    }

    x_fdatasync(fd);
    x_close(fd);
    x_renameat(qps->dfd, buf, qps->dfd, dst);
}

static qps_map_t *qps_pg_map_open(qps_t *qps, uint32_t no, uint32_t gen)
{
    qps_pghdr_t *hdrs;
    char buf[32];
    qps_map_t *map;
    gzFile zin;
    uint32_t pg;
    int  fd;

    snprintf(buf, sizeof(buf), "%08x.%08x.qpz", no, gen);
    map = qps_map_pg_create_raw(qps, no);

    if ((fd = openat(qps->dfd, buf, O_RDONLY, 0644)) < 0) {
        logger_error(&qps->logger, "[%s] unable to open file: %m", buf);
        return NULL;
    }

    zin = gzdopen(fd, "rb");
    if (zin == NULL) {
        logger_error(&qps->logger, "[%s] unable to gzdopen", buf);
        goto zerror;
    }

#if ZLIB_VERNUM >= 0x1240
    gzbuffer(zin, 1 << 20);
#endif
    if (gzread(zin, &map->hdr, sizeof(qps_map_t)) != sizeof(qps_map_t))
        goto zerror;

    map->hdr.generation = gen;
    pg = 1;

    MAP_HIDE(map, no * QPS_MAP_PAGES + 1, QPS_MAP_PAGES - 1);
    hdrs = &qps->hdrs[no * QPS_MAP_PAGES];

    while (pg < QPS_MAP_PAGES) {
        uint32_t blk = no * QPS_MAP_PAGES + pg;
        uint32_t tmp[2];
        uint16_t sz;

        if (gzread(zin, tmp, sizeof(tmp)) != sizeof(tmp))
            goto zerror;

        sz = tmp[0];
        if (sz == 0 || pg + sz > QPS_MAP_PAGES) {
            logger_error(&qps->logger, "[%s] invalid page metadata", buf);
            gzclose(zin);
            zin = NULL;
            goto zerror;
        }

        if (tmp[0] & (1 << 16)) {
            qps_pg_blk_insert(qps, blk, sz);
        } else {
            int rsz = sz * QPS_PAGE_SIZE;

            hdrs[pg].size   = sz;
            hdrs[pg].handle = tmp[1];
            hdrs[pg].flags |= QPS_BLK_USED;
            MAP_DEF(map, blk, sz);
            if (gzread(zin, map + pg, rsz) != rsz)
                goto zerror;
        }
        pg += sz;
    }

    gzclose(zin);
    return map;

  zerror:
    if (zin) {
        logger_error(&qps->logger, "[%s] unable to gzread(): %s", buf,
                     gzerror(zin, NULL));
        gzclose(zin);
    }
    qps_map_recycle(qps, map, no, false);
    return NULL;
}

static qps_map_t *qps_m_map_open(qps_t *qps, uint32_t no)
{
    int fd;
    char buf[32];
    qps_map_t *map = NULL;
    qps_map_t  hdr;
    struct stat st = { .st_size = 0 };

    snprintf(buf, sizeof(buf), "%08x.qps", no);
    logger_trace(&qps->logger, 1, "openat(%s)", buf);
    if ((fd = openat(qps->dfd, buf, O_RDONLY)) < 0) {
        logger_error(&qps->logger, "[%s] unable to open: %m", buf);
        return NULL;
    }
    if (fstat(fd, &st) < 0 || st.st_size != QPS_MAP_SIZE) {
        logger_error(&qps->logger, "[%s] invalid size %#jx", buf, st.st_size);
        goto err_close;
    }

    if (qps->maps.len > (int)no) {
        map = qps->maps.tab[no];
    }
    map = qps_map_fd(qps, fd, map);
    p_close(&fd);
    if (memcmp(map->hdr.sig, QPS_MAP_MEM_SIG, sizeof(QPS_MAP_MEM_SIG))) {
        logger_error(&qps->logger, "[%s] invalid signature", buf);
        goto err_unmap;
    }
    if (map->hdr.mapno != no) {
        logger_error(&qps->logger, "[%s] invalid mapno", buf);
        goto err_unmap;
    }

    /* The header contains runtime informations, so it must be writable but
     * we don't care about the result, so put it in an anonymous map.
     */
    hdr.hdr = map->hdr;
    hdr.hdr.qps = qps;
    hdr.hdr.disk_usage = st.st_blocks * 512;
    x_mmap(map, sizeof(hdr), PROT_READ | PROT_WRITE,
           MAP_SHARED | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    map->hdr = hdr.hdr;
    return map;

  err_unmap:
    qps_map_recycle(qps, map, no, true);
    return NULL;

  err_close:
    p_close(&fd);
    return NULL;
}

void qps_enospc(qps_t *nullable qps, const char *what)
{
    if (_G.in_snapshot_fork) {
        logger_fatal(qps ? &qps->logger : &_G.logger,
                     "snapshotter-child: unexpected I/O error (%s:%m)",
                     what);
    }

    if (strequal(what, "mmap")) {
        logger_fatal(qps ? &qps->logger : &_G.logger,
                     "unexpected error (%s: %m)", what);
    } else {
        logger_fatal(qps ? &qps->logger : &_G.logger,
                     "unexpected I/O error (%s: %m)", what);
    }
}

static void qps_on_segfault(int signum, siginfo_t *si, void *uc)
{
    struct sigaction act = {
        .sa_handler = SIG_DFL,
    };
    int save_errno;

    if (signum == SIGBUS && si->si_code != BUS_ADRERR)
        goto not_for_us;
    if (signum == SIGSEGV && si->si_code != SEGV_ACCERR)
        goto not_for_us;

    save_errno = errno;
    dlist_for_each(it, &_G.qps_head) {
        qps_t     *qps = dlist_entry(it, qps_t, qps_link);
        qps_map_t *map = qps_map_of(si->si_addr);
        int        pos = qps_smaps_find(&qps->smaps, si->si_addr, true);

#ifdef OS_LINUX
        if (signum == SIGBUS && (pos >= 0 || map == qps->gc_map)) {
            logger_fatal(&qps->logger, "caught SIGBUS: disk is full");
        }
#endif

        if (pos >= 0) {
            if (!qps_map_is_pg(map)) {
                logger_error(&qps->logger, "trying to write into RO map "
                             "%p:"QPS_PG_FMT, qps, QPS_PG_ARG(map->hdr.mapno));
                break;
            }

            logger_trace(&qps->logger, 1, "page fault: mark %p:%d dirty",
                         qps, map->hdr.mapno);
            qps_map_protect(NULL, map, PROT_READ | PROT_WRITE);
            map->hdr.generation = qps->generation;
            errno = save_errno;
            return;
        }
    }

    errno = save_errno;
  not_for_us:
    if (_G.sighandler) {
        (*_G.sighandler)(signum, si, uc);
    } else {
        sigaction(signum, &act, NULL);
        raise(signum);
    }
}

/* }}} */
/** @} */
/** @{ \name Internal: meta-data helpers */
/* {{{ */

/* XXX: this is an unsafe operation since it *can* destroy files we don't want
 * to once a GC has been run, so never run it after a GC has taken place.
 *
 * Only safe moments are:
 *   - just after opening a QPS;
 *   - after a snapshot has taken place and before any GC has taken place.
 */
static void qps_dir_cleanup(qps_t *qps, uint32_t gen)
{
    struct dirent *de;
    DIR           *dir = NULL;

    dir = fdopendir(dup(qps->dfd));
    if (!dir) {
        logger_error(&qps->logger, "[%p] unable to fdopendir: %m", qps);
        return;
    }

    rewinddir(dir);
    while ((de = readdir(dir))) {
        const char *s   = de->d_name;
        const char *ext = path_extnul(s);

        if (strequal(ext, ".qpt")) {
            logger_trace(&qps->logger, 1, "unlinkat(%s)", s);
            unlinkat(qps->dfd, s, 0);
            continue;
        }

        if (strequal(ext, ".qps")) {
            if (strequal(s, "meta.qps"))
                continue;
            if (strlen(s) != 8 + 4) {
                logger_trace(&qps->logger, 1, "unlinkat(%s)", s);
                unlinkat(qps->dfd, s, 0);
            } else {
                uint32_t no = strtol(s, NULL, 16);

                if (no >= (uint32_t)qps->maps.len
                ||  qps->maps.tab[no] == NULL)
                {
                    logger_trace(&qps->logger, 1, "unlinkat(%s)", s);
                    unlinkat(qps->dfd, s, 0);
                }
            }
            continue;
        }

        if (strequal(ext, ".qpz")) {
            if (strlen(s) == 8 + 1 + 8 + 4
            &&  s[8] == '.'
            &&  (uint32_t)strtoul(s + 9, NULL, 16) == gen)
            {
                continue;
            }
            logger_trace(&qps->logger, 1, "unlinkat(%s)", s);
            unlinkat(qps->dfd, s, 0);
        }
    }
    closedir(dir);
}

/** A conveniency structure to describe a \p meta.qps header */
struct qps_meta {
    uint8_t  sig[16];    /**< Holds the \p maps.qps signature */
    uint32_t generation; /**< Holds the \p maps.qps generation */
    uint32_t osize;      /**< original size of the compressed data */
    uint32_t csize;      /**< size of the following compressed data */
    uint32_t psize;      /**< size of the private data */
    uint32_t pcsize;     /**< size of the compressed private data */
    uint8_t  data[];     /**< beginning of the compressed data */
};

/** means that the map is a paged allocator map */
#define QPS_META_MAP_PAGED   (1U << 16)
/** means that the map is a tlsf allocator map */
#define QPS_META_MAP_TLSF    (2U << 16)

/** Write the \p meta.qpt file for a QPS.
 *
 * This function is on the safe side and performs calls to fdatasync(). Be
 * careful to use an efficient file-system for QPS !
 */
static void x_write_meta(qps_t *qps, uint32_t generation, const qv_t(u32) t,
                         const void *priv, size_t plen)
{
    t_scope;
    size_t csz;
    struct qps_meta m = { .generation = generation };
    int fd;
    sha1_ctx ctx;
    void *o, *p, *buf;

    fd = qps_open_temp(qps, "meta.qpt");
    buf = t_new_raw(char, LZO_BUF_MEM_SIZE);

    memcpy(m.sig, QPS_META_SIG, sizeof(QPS_META_SIG));

    m.osize      = t.len * sizeof(uint32_t);
    csz          = lzo_cbuf_size(m.osize);
    o            = t_new_raw(char, csz);
    m.csize      = qlzo1x_compress(o, csz, ps_init(t.tab, m.osize), buf);

    m.psize      = plen;
    csz          = lzo_cbuf_size(m.psize);
    p            = t_new_extra(char, csz);
    m.pcsize     = qlzo1x_compress(p, csz, ps_init(priv, m.psize), buf);

    sha1_starts(&ctx);
    sha1_update(&ctx, &m, sizeof(m));
    sha1_update(&ctx, o, m.csize);
    sha1_update(&ctx, p, m.pcsize);
    sha1_finish(&ctx, buf);

    x_write(fd, &m, sizeof(m));
    x_write(fd, o, m.csize);
    x_write(fd, p, m.pcsize);
    x_write(fd, buf, 20);
    x_fdatasync(fd);
    x_close(fd);
}

/* XXX: In case of success don't forget to unmap */
static
int qps_map_meta(const qps_t *qps, struct qps_meta **_meta, size_t *size)
{
    const ssize_t min_sz = sizeof(struct qps_meta) + 20;
    int fd;
    struct stat st;
    struct qps_meta *meta;

    *_meta = NULL;
    *size = 0;

    if ((fd = openat(qps->dfd, "meta.qps", O_RDONLY)) < 0) {
        return logger_error(&qps->logger, "[meta] unable to open: %m");
    }
    if (fstat(fd, &st) < 0) {
        logger_error(&qps->logger, "[meta] unable to stat: %m");
        goto err_close;
    }
    if (st.st_size < min_sz) {
        logger_error(&qps->logger, "[meta] invalid file size: %zd",
                     st.st_size);
        goto err_close;
    }
    meta = x_mmap(NULL, st.st_size, PROT_READ, MAP_SHARED, fd, 0);
    p_close(&fd);

    {
        uint8_t shabuf[20];

        if (memcmp(meta->sig, QPS_META_SIG, sizeof(QPS_META_SIG))) {
            logger_error(&qps->logger, "[meta] invalid signature");
            goto err_unmap;
        }
        sha1(meta, st.st_size - sizeof(shabuf), shabuf);
        if (memcmp(meta->data + st.st_size - min_sz, shabuf, sizeof(shabuf))) {
            logger_error(&qps->logger, "[meta] wrong sha1 signature");
            goto err_unmap;
        }
        if (st.st_size - min_sz != meta->csize + meta->pcsize) {
            logger_error(&qps->logger, "[meta] unexpected csize/pcsize");
            goto err_unmap;
        }
        if (meta->generation == 0) {
            logger_error(&qps->logger, "[meta] unexpected generation");
            goto err_unmap;
        }
    }

    *_meta = meta;
    *size = st.st_size;
    return 0;

  err_close:
    p_close(&fd);
    return -1;

  err_unmap:
    x_munmap(meta, st.st_size);
    return -1;
}

/* XXX: out MUST be allocated before calling. */
static
int qps_unlzo_data(qps_t *qps, const void *data, size_t datasz,
                   size_t outsz, void *out)
{
    ssize_t   res;

    res  = qlzo1x_decompress(out, outsz, ps_init(data, datasz));
    if (res < 0) {
        return logger_error(&qps->logger, "unable to unLZO: %zd", -res);
    } else
    if ((size_t)res != outsz) {
        return logger_error(&qps->logger, "unexpected unLZO size: %zd", res);
    }
    return 0;
}

/** Loads a \p meta.qps file at qps_open() time.
 *
 * This function makes a lot of checks, mostly to help debugging.
 * Note that it will qps_map_unlink() an map that looks empty. Be careful,
 * this can be a destructive operation
 */
static int qps_load_meta(qps_t *qps, sb_t *out, bool ro)
{
    t_scope;
    struct qps_meta *meta;
    size_t meta_size;
    qps_map_t *map = NULL;
    uint32_t *h_u32, *u32, *uend;
    uint32_t h_len;
    int ret_val = 0;

    RETHROW(qps_map_meta(qps, &meta, &meta_size));

    if (unlikely(meta->generation % 2 == 0)) {
        logger_trace(&qps->logger, 0,
                     "should not happen: backward compat for old bug");
        qps->generation = meta->generation + 3;
    } else {
        qps->generation = meta->generation + 2;
    }

    if (out) {
        void *buf = sb_growlen(out, meta->psize);

        if (qps_unlzo_data(qps, meta->data + meta->csize, meta->pcsize,
                           meta->psize, buf) < 0)
        {
            goto err_unmap;
        }
    }

    if (meta->osize == 0) {
        goto ok_unmap;
    }

    u32  = t_new_raw(uint32_t, meta->osize / 4);
    uend = u32 + meta->osize / 4;
    if (qps_unlzo_data(qps, meta->data, meta->csize, meta->osize, u32) < 0) {
        goto err_unmap;
    }

    h_len = DIV_ROUND_UP(u32[0], QPS_HANDLES_COUNT);
    p_realloc(&qps->handles, h_len);
    qps->handles_max      = u32[0];
    qps->handles_freelist = u32[1];
    h_u32 = u32 + 2;
    u32 = h_u32 + h_len;

    if (u32 + 1 + u32[0] * 2 != uend) {
        logger_error(&qps->logger, "[meta] inconsistent meta.qps [1]");
        goto err_unmap;
    }
    u32++;

    for (; u32 < uend; u32 += 2) {
        uint16_t no = u32[0];

        if (no < qps->maps.len && qps->maps.tab[no]) {
            logger_error(&qps->logger, "[meta] inconsistent meta.qps [2]");
            goto err_unmap;
        }
        for (uint32_t i = qps->maps.len; i < no; i++)
            qv_append(&qps->no_free, i);

        qps_alloc_hdrs(qps, qps->maps.len, no);
        if (u32[0] & QPS_META_MAP_TLSF) {
            map = qps_m_map_open(qps, no);
            if (!map) {
                logger_error(&qps->logger,
                             "[meta] inconsistent meta.qps [3]");
                goto err_unmap;
            }
            if (QPS_GEN_CMP(map->hdr.generation, >, meta->generation)) {
                logger_error(&qps->logger,
                             "[meta] inconsistent meta.qps [4]");
                goto err_unmap;
            }
            if (u32[1] > map->hdr.allocated) {
                logger_error(&qps->logger,
                             "[meta] inconsistent meta.qps [5]");
                goto err_unmap;
            }
            map->hdr.remaining = u32[1];
            if (u32[1] == 0)
                qps_map_recycle(qps, map, no, true);
        } else
        if (!(u32[0] & QPS_META_MAP_PAGED)) {
            logger_error(&qps->logger, "[meta] inconsistent meta.qps [6]");
            goto err_unmap;
        } else {
            map = qps_pg_map_open(qps, no, meta->generation);
            if (!map) {
                logger_error(&qps->logger,
                             "[meta] inconsistent meta.qps [7]");
                goto err_unmap;
            }
        }

        qps_map_protect(qps, map, PROT_READ);
        qps_map_bless(qps, map);
    }
    for (size_t i = 0; i < h_len; i++) {
        qps->handles[i] = qps_pg_deref(qps, h_u32[i]);
    }

  ok_unmap:
    x_munmap(meta, meta_size);

#ifdef NDEBUG
    if (ro) {
#endif
    tab_for_each_pos (pos, &qps->maps) {
        qps_map_t *m = qps->maps.tab[pos];
        int ret;

        if (!m) {
            continue;
        } else
        if (qps_map_is_pg(m)) {
            ret = qps_pg_check_hdrs_aux(qps, m->hdr.mapno << 16, false);
        } else {
            ret = qps_m_check_map(qps, m, false);
            qps_m_malloclike_map(qps, map);
        }
        if (ret < 0) {
            ret_val = -1;
            logger_error(&qps->logger, "[meta] inconsistent meta.qps [8]:"
                         " map %08x is invalid", pos);
        }
    }
#ifdef NDEBUG
    }
#endif
    return ret_val;

  err_unmap:
    x_munmap(meta, meta_size);
    return -1;
}

/** QPS initializer.  */
static qps_t *qps_new(int dfd, const char *name)
{
    qps_t *qps = p_new(qps_t, 1);

    MODULE_REQUIRE(qps);
    logger_init(&qps->logger, &_G.logger, LSTR(name), LOG_INHERITS, 0);
    logger_init(&qps->tracing_logger, &qps->logger, LSTR("tracing"),
                LOG_INHERITS, LOG_SILENT);
    qps->dfd = dfd;
    qps->lock = DIR_LOCK_INIT_V;
    qps->generation = 1;
    qps->handles_gc_gen = 1;
    thr_syn_init(&qps->gc_syn);
    thr_syn_init(&qps->snap_syn);
    qps->hdrs = p_new(qps_pghdr_t, 1);

    dlist_add(&_G.qps_head, &qps->qps_link);
    return qps;
}


/* }}} */
/** @} */
/** @{ \name Internal: GC Helpers */
/* {{{ */

static void qps_free_ro(qps_t *qps, qps_map_t *map, size_t bsz)
{
    assert (map->hdr.remaining >= bsz + QPS_MBLK_HDRSZ);
    map->hdr.remaining -= bsz + QPS_MBLK_HDRSZ;
    if (map->hdr.remaining == 0) {
        logger_trace(&qps->logger, 1, "map %x empty", map->hdr.mapno);
        madvise(&map[1], QPS_MAP_SIZE - QPS_PAGE_SIZE, MADV_DONTNEED);
    }
}

static int
qps_gc_compact(qps_t *qps, uint32_t no, qps_map_t *map, qv_t(qps_gcmap) maps)
{
    void       *map_end = &map[QPS_MAP_PAGES];
    qps_mhdr_t *dst_end = container_of(map_end, qps_mhdr_t, data);
    qps_mhdr_t *dst     = (qps_mhdr_t *)&map[1];

    assert (!qps->snapshotting);
    dst->flags = QPS_MBLK_HDRSZ | QPS_BLK_PREV_USED | QPS_BLK_USED;
    dst = qps_m_blk_next(dst, QPS_MBLK_HDRSZ);
    dst_end->flags = 0 | QPS_BLK_USED;

    for (int i = 0; i < maps.len; i++) {
        qps_map_t  *src_map = maps.tab[i].map;
        qps_mhdr_t *src     = (qps_mhdr_t *)&src_map[1];
        void       *smapend = &src_map[QPS_MAP_PAGES];
        qps_mhdr_t *src_end = container_of(smapend, qps_mhdr_t, data);
        qps_mhdr_t *next;

        for (src = qps_m_blk_next(src, QPS_MBLK_HDRSZ); src < src_end; src = next) {
            uint32_t   size = qps_m_blk_size(src);
            qps_ptr_t *hptr, bptr;

            next = qps_m_blk_next(src, size);
            if (src->flags & QPS_BLK_FREE)
                continue;
            hptr = qps_handle_slot(qps, src->handle);
            bptr = qps_encode(src->data);
            if (hptr->pgno != bptr.pgno || hptr->addr != bptr.addr)
                continue;
            if (qps_m_blk_next(dst, size) + sizeof(qps_mhdr_t) > dst_end) {
                /*
                 * Destination page cannot hold this pointer.
                 *
                 * We will leave some freespace at the end with this sloppy
                 * test, but the map will be writeable and will have a change
                 * to be filled, so don't bother finding a suitable block to
                 * fill that gap.
                 */
                goto end;
            }
            *hptr       = qps_encode(dst->data);
            dst->flags  = size | QPS_BLK_USED | QPS_BLK_PREV_USED;
            dst->handle = src->handle;
            dst         = mempcpy(dst->data, src->data, size);
            map->hdr.allocated += size + QPS_MBLK_HDRSZ;
            qps_free_ro(qps, src_map, size);
        }

        assert (src_map->hdr.remaining == 0);
    }

  end:
    qps->handles_gc_gen += 2;
    qps_map_bless(qps, map);
    qps_m_blk_insert(qps, dst, (uint8_t *)dst_end - dst->data);

    logger_trace(&qps->tracing_logger, 1, "gc compaction done");
    qv_wipe(&maps);
    assert (!qps->snapshotting);
    atomic_fetch_sub(&qps->gc_state, 2);
    return 0;
}

static void qps_gc(qps_t *qps, uint32_t gc_gen)
{
    uint64_t allocated = 0, disk_usage = 0;
    uint_fast16_t enabled = QPS_GC_ENABLED;
    qv_t(qps_gcmap) maps;

    assert (!qps->snapshotting);
    if (atomic_load(&qps->gc_gen) != gc_gen) {
        logger_trace(&qps->tracing_logger, 2, "ignored stalled gc");
        return;
    }
    if (!atomic_compare_exchange_strong(&qps->gc_state, &enabled,
                                        QPS_GC_RUNNING))
    {
        logger_trace(&qps->tracing_logger, 2, "ignored cancelled gc");
        return;
    }

    logger_trace(&qps->tracing_logger, 1, "start gc");
    qps_m_check_maps(qps);

    qv_init(&maps);
    tab_for_each_pos(i, &qps->maps) {
        qps_map_t  *map = qps->maps.tab[i];
        qps_gcmap_t m   = { .map = map };

        if (!map || map->hdr.generation == 0 || qps_map_is_pg(map))
            continue;
        /* ignore files that are too recent (less than a generation old) */
        if (qps->generation - map->hdr.generation <= 2)
            continue;
        if (map->hdr.remaining == 0)
            continue;

        /* ignore files whose footprint on disk has less than 10% waste *and*
         * are bigger than 128M. Those are efficient enough.
         */
        atomic_thread_fence(memory_order_acquire);
        m.gen        = map->hdr.generation;
        m.allocated  = map->hdr.remaining;
        m.disk_usage = map->hdr.disk_usage;
        if (m.disk_usage == 0) /* XXX: only happens with eatmydata */
            continue;
        m.mark       = 10UL * m.allocated / m.disk_usage;
        if (m.mark > 9 && m.allocated > QPS_MAP_SIZE / 2)
            continue;
        allocated   += m.allocated;
        disk_usage  += m.disk_usage;
        qv_append(&maps, m);
    }

    if (maps.len == 0) {
        logger_trace(&qps->tracing_logger, 1, "nothing to gc");
        goto end_no_trace;
    }

    if (maps.len < 4 && allocated < QPS_MAP_SIZE / 2 && disk_usage < QPS_MAP_SIZE) {
        logger_trace(&qps->tracing_logger, 1, "nothing worthy to gc");
        goto end_no_trace;
    }

    qv_sort(qps_gcmap)(&maps, ^int (qps_gcmap_t const *m1, qps_gcmap_t const *m2) {
        return CMP(m1->mark, m2->mark) ?: qps_gen_cmp(m1->gen, m2->gen);
    });

    if (atomic_load(&qps->gc_state) == QPS_GC_RUNNING) {
        qps_map_t *map;
        uint32_t no;

        no = qps_map_find_no(qps);
        qps->gc_map = map = qps_map_m_create_raw(qps, no);
        map->hdr.generation = qps->generation;

        if (qps_gc_compact(qps, no, map, maps) < 0) {
            qps->gc_map = NULL;
            qps_map_recycle(qps, map, no, true);
            goto end;
        }
        return;
    }

  end:
    logger_trace(&qps->tracing_logger, 1, "cancelled gc");
  end_no_trace:
    qv_wipe(&maps);
    atomic_fetch_sub(&qps->gc_state, 2);
    qps_m_check_maps(qps);
}

static void qps_gc_on_idle(el_t ev, data_t priv)
{
    qps_t *qps = priv.ptr;

    if (atomic_load(&qps->gc_state) & QPS_GC_ENABLED) {
        if (atomic_load(&qps->gc_syn.pending) == 0) {
            uint32_t gc_gen = atomic_fetch_add(&qps->gc_gen, 1) + 1;

            logger_trace(&qps->tracing_logger, 1, "schedule gc");
            qps_gc(qps, gc_gen);
        }
    }
}

/** Enable the handle GC.
 *
 * The garbage collector is disabled by default.  Note that each time
 * qps_snapshot is called, qps snapshotting is disabled, it's up to the user
 * to handle gc reactivation.
 *
 * \warning it's invalid to activate the GC while a snapshot is going on!
 *
 * \return the previous state of the GC (true for enabled, false else).
 */
bool qps_gc_enable(qps_t *qps)
{
    int prev = atomic_fetch_or(&qps->gc_state, QPS_GC_ENABLED);

    logger_trace(&qps->tracing_logger, 1, "enable gc");
    if (thr_is_on_queue(thr_queue_main_g)) {
        qps_gc_on_idle(NULL, (data_t){ .ptr = qps });
    }
    return prev & QPS_GC_ENABLED;
}

/** Disable and cancels the handle GC.
 *
 * Disallow the execution of the garbage collection. Waits to be sure no GC is
 * currently running.
 *
 * \param[in]   qps   the qps
 * \param[in]   wait  whether it waits for GC job to be completely gone.
 *
 * \return the previous state of the GC (true for enabled, false else).
 */
bool qps_gc_disable(qps_t *qps)
{
    int prev = atomic_fetch_and(&qps->gc_state, ~QPS_GC_ENABLED);

    logger_trace(&qps->tracing_logger, 1, "disable gc");
    if (prev & QPS_GC_RUNNING)
        thr_syn_wait(&qps->gc_syn);
    return prev & QPS_GC_ENABLED;
}

/* }}} */
/** @} */
/* public: helpers {{{ */

static ALWAYS_INLINE void qps_zero_helper(uint8_t *p, uint8_t *end)
{
    uint8_t *q = p;

    mem_tool_allow_memory_if_addressable(p, end - p, true);
    if (end - p >= 64) {
        while ((uintptr_t)q & 7) {
            if (*q++)
                goto memset;
        }
        while (q + 8 * sizeof(size_t) < end) {
            size_t *t = (size_t *)q;
            if (t[0] | t[1] | t[2] | t[3] | t[4] | t[5] | t[6] | t[7])
                goto memset;
            q += 8 * sizeof(size_t);
        }
        while (q + sizeof(size_t) < end) {
            if (*(size_t *)q)
                goto memset;
            q += sizeof(size_t);
        }
    }
    while (q < end) {
        if (*q++)
            goto memset;
    }
    return;

  memset:
    memset(p, 0, end - p);
}

void qps_pg_zero(qps_t *qps, qps_pg_t blk, size_t n)
{
    uint8_t *p = qps_pg_deref(qps, blk);

    qps_zero_helper(p, p + QPS_PAGE_SIZE * n);
}

void qps_zero(qps_t *qps, void *p, size_t n)
{
    qps_zero_helper(p, (uint8_t *)p + n);
}

size_t qps_pg_sizeof(qps_t *qps, qps_pg_t blk)
{
    return qps->hdrs[blk].size;
}

size_t qps_sizeof(qps_t *qps, const void *ptr)
{
    if (ptr == NULL)
        return 0;
    if (qps_map_is_pg(qps_map_of(ptr)))
        return qps->hdrs[qps_pg_of(ptr)].size * QPS_PAGE_SIZE;
    return qps_m_blk_size(container_of((void *)ptr, qps_mhdr_t, data));
}

/* only used by qps_handle_deref to tag memory */
void qps_handle_allow_memory(qps_t *qps, qps_handle_t id, qps_ptr_t *ptr)
{
#if QPS_USE_REDZONES
    void *res = (uint8_t *)qps_pg_deref(qps, ptr->pgno) + ptr->addr;
    qps_mhdr_t *blk  = container_of(res, qps_mhdr_t, data);

    assert (blk->handle == id);
    assert (blk->rz_alloc_size);

    mem_tool_allow_memory(res, blk->rz_alloc_size, true);
#endif
}

/* }}} */
/* public: paged allocation {{{ */

static ALWAYS_INLINE qps_map_t *qps_pg_maphdr(const qps_t *qps, qps_pg_t pg)
{
    return qps->maps.tab[pg >> 16];
}
#define qps_pg_maphdr(qps, pg)  (&qps_pg_maphdr(qps, pg)->hdr)

static void qps_pg_unmap_int(qps_t *qps, qps_pg_t blk)
{
    qps_pghdr_t *hdr = qps->hdrs + blk;
    size_t       bsz = hdr->size;
    qps_pghdr_t *tmp = hdr + bsz;

    assert (blk < qps->maps.len * QPS_MAP_PAGES);
    assert (blk == 0 || (blk & 0xffff));

    qps_pg_check_hdrs(qps);
    qps_pg_maphdr(qps, blk)->allocated -= bsz * QPS_PAGE_SIZE;

    if (tmp->flags & QPS_BLK_FREE) {
        bsz += qps_pg_blk_remove(qps, blk + bsz);
    }
    if (hdr->flags & QPS_BLK_PREV_FREE) {
        blk  = hdr->blk_prev;
        bsz += qps_pg_blk_remove(qps, blk);
    }
    qps_pg_blk_insert(qps, blk, bsz);
    PG_HIDE(qps, blk, bsz);
    qps_pg_check_hdrs(qps);
}

static void qps_pg_unload_int(qps_t *qps, qps_pg_t blk)
{
    qps_pghdr_t *hdr  = qps->hdrs + blk;
    size_t       bsz  = hdr->size;
    void        *data = qps_pg_deref(qps, blk);

    madvise(data, bsz * QPS_PAGE_SIZE, MADV_DONTNEED);
}

static qps_pg_t qps_pg_map_int(qps_t *qps, uint32_t id, size_t n)
{
    uint32_t l1, l2;
    qps_pg_t blk;
    qps_pghdr_t *hdr;

    if (unlikely(n == 0))
        return QPS_PG_NULL;
    if (unlikely(n >= QPS_MAP_PAGES))
        return QPS_PG_NULL;

    if (unlikely(n * QPS_PAGE_SIZE > QPS_ALLOC_MAX))
        return QPS_PG_NULL;

    qps_pg_check_hdrs(qps);
    qps_pg_alloc_search(n, &l1, &l2);
    blk = qps_pg_find_blk(qps, n, &l1, &l2);
    if (unlikely(!blk)) {
        qps_map_create(qps, true);
        blk = qps_pg_find_blk(qps, n, &l1, &l2);
    }
    qps_pg_check_hdrs(qps);

    hdr = qps->hdrs + blk;
    if ((qps->pgs.blks[l1][l2] = hdr->free.next)) {
        qps->hdrs[hdr->free.next].free.prev = 0;
    } else {
        RST_BIT(qps->pgs.l2_bitmap + l1, l2);
        if (!qps->pgs.l2_bitmap[l1])
            RST_BIT(&qps->pgs.l1_bitmap, l1);
    }

    if (n < hdr->size) {
        /*
         * If allocation is too large
         * free() the end of the block back into the tlsf allocator
         */
        qps_pg_blk_insert(qps, blk + n, hdr->size - n);
        hdr->size = n;
    } else {
        qps_pghdr_t *next = qps->hdrs + blk + n;

        assert (hdr->size == n);
        assert ((blk + n) % QPS_MAP_PAGES == 0 || next->flags & QPS_BLK_PREV_FREE);
        next->flags &= ~QPS_BLK_PREV_FREE;
    }

    hdr->flags  = QPS_BLK_USED | QPS_BLK_PREV_USED;
    hdr->handle = id;
    qps_pg_maphdr(qps, blk)->allocated += n * QPS_PAGE_SIZE;
    if (unlikely(id))
        *qps_handle_slot(qps, id) = (qps_ptr_t){ .pgno = blk };
    qps_pg_check_hdrs(qps);
    PG_UNDEF(qps, blk, n);
    return blk;
}

static qps_pg_t qps_pg_remap_int(qps_t *qps, qps_pg_t blk, size_t nsz)
{
    qps_pghdr_t *hdr, *nxt;
    size_t bsz;

    assert (blk < qps->maps.len * QPS_MAP_PAGES);
    assert (blk == 0 || (blk & 0xffff));

    if (unlikely(nsz * QPS_PAGE_SIZE > QPS_ALLOC_MAX))
        return QPS_PG_NULL;

    qps_pg_check_hdrs(qps);
    hdr = qps->hdrs + blk;
    bsz = hdr->size;
    nxt = hdr + bsz;
    assert (bsz);
    if (nsz == bsz)
        return blk;
    if (nsz < bsz) {
        size_t tsz = bsz - nsz;

        if (nxt->flags & QPS_BLK_FREE)
            tsz += qps_pg_blk_remove(qps, blk + bsz);
        qps_pg_blk_insert(qps, blk + nsz, tsz);
        PG_HIDE(qps, blk + nsz, tsz);
    } else
    if ((nxt->flags & QPS_BLK_FREE) && bsz + nxt->size >= nsz) {
        size_t tsz = bsz + qps_pg_blk_remove(qps, blk + bsz);

        if (tsz > nsz)
            qps_pg_blk_insert(qps, blk + nsz, tsz - nsz);
        PG_UNDEF(qps, blk + nsz, tsz - nsz);
    } else {
        qps_pg_t res = qps_pg_map_int(qps, hdr->handle, nsz);

        if (unlikely(res == 0))
            return QPS_PG_NULL;
        memcpy(qps_pg_deref(qps, res), qps_pg_deref(qps, blk),
               QPS_PAGE_SIZE * bsz);
        qps_pg_unmap_int(qps, blk);
        return res;
    }

    hdr->size = nsz;
    qps_pg_maphdr(qps, blk)->allocated += (nsz - bsz) * QPS_PAGE_SIZE;
    qps_pg_check_hdrs(qps);
    return blk;
}

qps_pg_t qps_pg_map(qps_t *qps, size_t n)
{
    qps_pg_t res;

    TRACE_ALLOC("page", "pg_map  (%p, %zd) = ...", qps, n);
    res = qps_pg_map_int(qps, QPS_HANDLE_NULL, n);
    TRACE_ALLOC("page", "pg_map  (%p, %zd) = "QPS_PG_FMT,
                qps, n, QPS_PG_ARG(res));
    return res;
}

qps_pg_t qps_pg_remap(qps_t *qps, qps_pg_t blk, size_t nsz)
{
    qps_pg_t res;

    TRACE_ALLOC("page", "pg_remap(%p, "QPS_PG_FMT", %zd) = ...",
                qps, QPS_PG_ARG(blk), nsz);
    if (blk == 0) {
        res = qps_pg_map_int(qps, QPS_HANDLE_NULL, nsz);
    } else
    if (nsz == 0) {
        qps_pg_unmap_int(qps, blk);
        res = QPS_PG_NULL;
    } else {
        res = qps_pg_remap_int(qps, blk, nsz);
    }
    TRACE_ALLOC("page", "pg_remap(%p, "QPS_PG_FMT", %zd) = "QPS_PG_FMT,
                qps, QPS_PG_ARG(blk), nsz, QPS_PG_ARG(res));
    return res;
}

void qps_pg_unmap(qps_t *qps, qps_pg_t blk)
{
    TRACE_ALLOC("page", "pg_unmap(%p, "QPS_PG_FMT")", qps, QPS_PG_ARG(blk));
    if (likely(blk))
        qps_pg_unmap_int(qps, blk);
}

void qps_pg_unload(qps_t *qps, qps_pg_t blk)
{
    if (likely(blk))
        qps_pg_unload_int(qps, blk);
}

/* }}} */
/* public: memory allocation {{{ */

static void qps_free_int(qps_t *qps, void *ptr)
{
    qps_map_t  *map = qps_map_of(ptr);
    qps_mhdr_t *blk;
    size_t bsz;

    if (qps_map_is_pg(map)) {
        qps_pg_unmap_int(qps, qps_pg_of(ptr));
        return;
    }

    blk = container_of(ptr, qps_mhdr_t, data);
    bsz = qps_m_blk_size(blk);
#if QPS_USE_REDZONES
    mem_tool_freelike(ptr, blk->rz_alloc_size, 8);
#endif

    if (!qps_is_ro(qps, map)) {
        qps_mhdr_t *tmp = qps_m_blk_next(blk, bsz);

#if QPS_USE_REDZONES
        blk->rz_alloc_size = 0;
#endif
        map->hdr.allocated -= bsz + QPS_MBLK_HDRSZ;
        if (tmp->flags & QPS_BLK_FREE) {
            bsz += qps_m_blk_remove(qps, tmp) + QPS_MBLK_HDRSZ;
        }
        if (blk->flags & QPS_BLK_PREV_FREE) {
            blk  = qps_m_blk_get_prev(blk);
            bsz += qps_m_blk_remove(qps, blk) + QPS_MBLK_HDRSZ;
        }
        qps_m_blk_insert(qps, blk, bsz);
    } else {
        qps_free_ro(qps, map, bsz);
    }
}

static void *qps_alloc_int(qps_t *qps, uint32_t id, size_t asked)
{
    uint32_t l1, l2;
    qps_mhdr_t *blk, *next, *split;
    size_t tmp, size = asked;
    qps_ptr_t res;

    assert (id);
    if (unlikely(size >= QPS_M_ALLOC_MAX)) {
        qps_pg_t pg =
            qps_pg_map_int(qps, id, DIV_ROUND_UP(size, QPS_PAGE_SIZE));
        return qps_pg_deref(qps, pg);
    }

    if (size < QPS_ALLOC_MIN) {
        size = QPS_ALLOC_MIN;
    } else {
        size = ROUND_UP(size, 1 << QPS_ML2_OFFSET);
    }
    size = qps_m_alloc_search(size, &l1, &l2);
    blk  = qps_m_find_blk(qps, size, &l1, &l2);
    if (unlikely(!blk)) {
        qps_map_create(qps, false);
        blk = qps_m_find_blk(qps, size, &l1, &l2);
        assert (blk);
    }

    /* remove the block from the free-list and update bitfields */
    if ((qps->m.blks[l1][l2] = blk->free.next)) {
        blk->free.next->free.prev_next = &qps->m.blks[l1][l2];
    } else {
        RST_BIT(qps->m.l2_bitmap + l1, l2);
        if (!qps->m.l2_bitmap[l1])
            RST_BIT(&qps->m.l1_bitmap, l1);
    }

    tmp  = qps_m_blk_size(blk);
    next = qps_m_blk_next(blk, tmp);
    tmp -= size;
    if (tmp >= sizeof(qps_mhdr_t)) {
        split = qps_m_blk_next(blk, size);
        qps_m_blk_insert(qps, split, tmp - QPS_MBLK_HDRSZ);
        assert (qps_m_blk_get_prev(next) == split);
        qps_m_blk_set_prev_free(next, split);
#if QPS_USE_REDZONES
        split->rz_alloc_size = 0;
#endif
        assert (!(blk->flags & QPS_BLK_PREV_FREE));
        blk->flags = size;
    } else {
        next->flags &= ~QPS_BLK_PREV_FREE;
        blk->flags  &= ~QPS_BLK_FREE;
        size        += tmp;
    }

    blk->handle = id;
    qps_map_of(blk)->hdr.allocated += size + QPS_MBLK_HDRSZ;
    *qps_handle_slot(qps, id) = res = qps_encode(blk->data);
#if QPS_USE_REDZONES
    mem_tool_malloclike(blk->data, asked, 8, false);
    mem_tool_allow_memory(blk->data, asked, false);
    mem_tool_allow_memory(&blk->rz_alloc_size, 8, true);
    blk->rz_alloc_size = asked;
#endif
    return blk->data;
}

static void *qps_realloc_int(qps_t *qps, uint32_t id, void *ptr, size_t asked)
{
    qps_map_t *map = qps_map_of(ptr);
    size_t nsz = asked;

    assert (id);
    assert (ptr);
    if (nsz < QPS_ALLOC_MIN) {
        nsz = QPS_ALLOC_MIN;
    } else {
        nsz = ROUND_UP(nsz, 1 << QPS_ML2_OFFSET);
    }

    if (qps_map_is_pg(map)) {
        if (nsz >= QPS_M_ALLOC_MAX) {
            qps_pg_t pg = qps_pg_of(ptr);

            nsz = DIV_ROUND_UP(nsz, QPS_PAGE_SIZE);
            return qps_pg_deref(qps, qps_pg_remap_int(qps, pg, nsz));
        }
    } else {
        qps_mhdr_t *blk  = container_of(ptr, qps_mhdr_t, data);
        size_t      osz  = qps_m_blk_size(blk);
        qps_mhdr_t *next = qps_m_blk_next(blk, osz);
        size_t tsz;

        assert (blk->handle == id && osz);
        if (qps_is_ro(qps, map))
            goto alloc_copy_and_free;

        if (nsz <= osz) {
            if (next->flags & QPS_BLK_FREE) {
                tsz  = qps_m_blk_remove(qps, next);
                tsz += osz + QPS_MBLK_HDRSZ;
                goto split;
            }
            if (osz >= sizeof(qps_mhdr_t) + nsz) {
                tsz  = osz;
                goto split;
            }
#if QPS_USE_REDZONES
            mem_tool_freelike(blk->data, osz, 8);
            mem_tool_malloclike(blk->data, asked, 8, false);
            mem_tool_allow_memory(blk->data, asked, true);
            blk->rz_alloc_size = asked;
#endif
            return blk->data;
        }
        if ((next->flags & QPS_BLK_FREE) && nsz <= osz + qps_m_blk_size(next)
        &&   nsz < QPS_M_ALLOC_MAX)
        {
            tsz  = qps_m_blk_remove(qps, next);
            tsz += osz + QPS_MBLK_HDRSZ;

            if (tsz >= sizeof(qps_mhdr_t) + nsz) {
                qps_mhdr_t *split;

              split:
                split = qps_m_blk_next(blk, nsz);
                qps_m_blk_insert(qps, split, tsz - QPS_MBLK_HDRSZ - nsz);
            } else {
                nsz = tsz;
                qps_m_blk_next(blk, nsz)->flags &= ~QPS_BLK_PREV_FREE;
            }
        } else {
            goto alloc_copy_and_free;
        }

        blk->flags &= QPS_BLK_PREV_FREE;
        blk->flags += nsz;
        qps_map_of(blk)->hdr.allocated += nsz - osz;
#if QPS_USE_REDZONES
        mem_tool_freelike(blk->data, osz, 8);
        mem_tool_malloclike(blk->data, asked, 8, false);
        mem_tool_allow_memory(blk->data, osz, true);
        blk->rz_alloc_size = asked;
#endif
        return blk->data;
    }

  alloc_copy_and_free:
    {
        void *dst = qps_alloc_int(qps, id, nsz);

        if (likely(dst)) {
            size_t sz = qps_sizeof(qps, ptr);

#if QPS_USE_REDZONES
            if (!qps_map_is_pg(map)) {
                /* The 'asked' value of the previous alloc of ptr is lost
                 * during alloc. Only rounded upper value have been used to
                 * do the alloc, and should be sz if all went well. As we will
                 * copy the entire data[] array, we might possibly read data
                 * after 'asked' bytes, whihc is tagged as unaddressable.
                 * Copying this extra data is fine, and we should not report
                 * any memory error here. To avoid this cas, we have stored
                 * this 'asked' value in the rz_alloc_size field (only in this
                 * mode of course). Then, we can mark the trailing data
                 * ]asked, sz] as defined, just for the memcpy call */
                qps_mhdr_t *blko = container_of(ptr, qps_mhdr_t, data);
                qps_mhdr_t *blkn = container_of(dst, qps_mhdr_t, data);

                assert (blko->rz_alloc_size <= sz);
                assert (blkn->rz_alloc_size == nsz);
                if (asked != nsz) {
                    /* reajust this size as we know original asked value */
                    mem_tool_freelike(blkn->data, nsz, 8);
                    mem_tool_malloclike(blkn->data, asked, 8, false);
                    mem_tool_allow_memory(blkn->data, asked, true);
                    blkn->rz_alloc_size = asked;
                }
                memcpy(dst, ptr, MIN(asked, blko->rz_alloc_size));
                qps_free_int(qps, ptr);
                return dst;
            }
#endif
            if (sz > nsz)
                sz = nsz;
            memcpy(dst, ptr, sz);
            qps_free_int(qps, ptr);
        }
        return dst;
    }
}

static uint32_t qps_handle_new(qps_t *qps)
{
    uint32_t id = qps->handles_freelist;

    if (id) {
        qps->handles_freelist = qps_handle_slot(qps, id)->addr;
        return id;
    }
    if (unlikely(qps->handles_max % QPS_HANDLES_COUNT == 0)) {
        size_t len = qps->handles_max / QPS_HANDLES_COUNT;
        qps_pg_t pg;

        p_realloc(&qps->handles, len + 1);
        pg = qps_pg_map(qps, QPS_HANDLES_PAGES);
        qps_pg_zero(qps, pg, QPS_HANDLES_PAGES);
        qps->handles[len] = qps_pg_deref(qps, pg);
        if (qps->handles_max == 0)
            qps->handles_max++;
    }
    id = qps->handles_max++;
    return id;
}

static void qps_handle_free(qps_t *qps, uint32_t id)
{
    qps_ptr_t *ptr = qps_handle_slot(qps, id);

    *ptr = (qps_ptr_t){ .addr = qps->handles_freelist };
    qps->handles_freelist = id;
}

void *qps_alloc(qps_t *qps, uint32_t *id, size_t size)
{
    qps_handle_t h = QPS_HANDLE_NULL;
    void *res = NULL;

    qps_m_check_maps(qps);
    TRACE_ALLOC("frag", "alloc  (%p, ??, %zd) = ...", qps, size);
    if (likely(size < QPS_ALLOC_MAX)) {
        *id = h = qps_handle_new(qps);
        res = qps_alloc_int(qps, h, size);
    }
    TRACE_ALLOC("frag", "alloc  (%p, %d, %zd) = "QPS_PTR_FMT" (%zd)",
                qps, h, size, QPS_PTR_ARG(qps_encode(res)),
                qps_sizeof(qps, qps_handle_deref(qps, *id)));
    qps_m_check_maps(qps);
    return res;
}

void *qps_realloc(qps_t *qps, uint32_t id, size_t nsz)
{
    void *res;

    qps_m_check_maps(qps);
    TRACE_ALLOC("frag", "realloc(%p, %d, %zd) = ...", qps, id, nsz);
    res = qps_realloc_int(qps, id, qps_handle_deref(qps, id), nsz);
    TRACE_ALLOC("frag", "realloc(%p, %d, %zd) = "QPS_PTR_FMT" (%zd)",
                qps, id, nsz, QPS_PTR_ARG(qps_encode(res)),
                qps_sizeof(qps, qps_handle_deref(qps, id)));
    qps_m_check_maps(qps);
    return res;
}

void qps_free(qps_t *qps, uint32_t id)
{
    TRACE_ALLOC("frag", "dealloc(%p, %d)", qps, id);

    qps_m_check_maps(qps);
    if (likely(id)) {
        qps_free_int(qps, qps_handle_deref(qps, id));
        qps_handle_free(qps, id);
    }
    qps_m_check_maps(qps);
}

void *qps_w_deref_(qps_t *qps, uint32_t h, void *pptr)
{
    void     *rptr = NULL;
    qps_mhdr_t *blk = container_of(pptr, qps_mhdr_t, data);
    size_t    sz   = qps_m_blk_size(blk);

    qps_m_check_maps(qps);
    TRACE_ALLOC("frag", "w_deref(%p, %d, "QPS_PTR_FMT") = ...",
                qps, h, QPS_PTR_ARG(qps_encode(pptr)));
    rptr = qps_alloc_int(qps, h, sz);
#if QPS_USE_REDZONES
    sz = MIN(sz, blk->rz_alloc_size);
#endif
    memcpy(rptr, pptr, sz);
    qps_free_ro(qps, qps_map_of(pptr), sz);
    TRACE_ALLOC("frag", "w_deref(%p, %d, "QPS_PTR_FMT") = "QPS_PTR_FMT,
                qps, h, QPS_PTR_ARG(qps_encode(pptr)),
                QPS_PTR_ARG(qps_encode(rptr)));
    qps_m_check_maps(qps);
    return rptr;
}

/* }}} */
/* public: QPS manipulation {{{ */

static int qps_lock(qps_t *qps)
{
    if (lockdir(qps->dfd, &qps->lock) < 0) {
        return logger_error(&qps->logger, "unable to lock: %m");
    }
    return 0;
}

static int qps_lock_snapshot(qps_t *qps, dir_lock_t *dlock)
{
    const char *path = ".snapshotter-lock/";
    int ret;
    int fd;

    if (mkdirat_p(qps->dfd, path, 0755) < 0) {
        return logger_error(&qps->logger, "unable to create `%s`: %m", path);
    }
    if ((fd = openat(qps->dfd, path, O_RDONLY)) < 0) {
        return logger_error(&qps->logger, "unable to open `%s`: %m", path);
    }
    ret = lockdir(fd, dlock);
    p_close(&fd);
    return ret;
}

/** open a qps store.
 *
 * \param[in]  path
 *   path to the qps spool, a qps spool must live here.
 *
 * \param[in]  name
 *   name of the qps spool; is used to create the QPS loggers (so must be
 *   compatible with logger names, and be unique).
 *
 * \param[in]  priv
 *   a sb_t to hold the private metadata serialized along the QPS. May be NULL
 *   in which case the metadata are ignored.
 *
 * \return
 *   - NULL if it failed, e_error is used to log why it failed
 *   - a pointer to the created qps object.
 */
qps_t *qps_open(const char *path, const char *name, sb_t *priv)
{
    dir_lock_t  snapshot_lock;
    struct stat st;
    qps_t      *qps;
    int         fd;

    STATIC_ASSERT(sizeof(qps_map_t) == QPS_PAGE_SIZE);
    STATIC_ASSERT(offsetof(qps_map_t, hdr.qps) == QPS_PAGE_SIZE / 2);
    STATIC_ASSERT(QPS_ALLOC_MIN >= fieldsizeof(qps_mhdr_t, padding));

    fd  = RETHROW_NP(open(path, O_RDONLY));
    qps = qps_new(fd, name);
    qps->gc_idle = el_idle_register(qps_gc_on_idle, qps);
    el_unregister(&qps->gc_idle);

    if (qps_lock(qps) < 0) {
        goto out_close;
    }
    if (qps_lock_snapshot(qps, &snapshot_lock) < 0) {
        logger_error(&qps->logger, "cannot take snapshotter lock: "
                     "background snapshot in progress?");
        goto out_close;
    }
    unlockdir(&snapshot_lock);

    if (fstatat(fd, "meta.qps", &st, 0) < 0) {
        logger_error(&qps->logger, "unable to stat meta.qps: %m");
        goto out_close;
    }
    /* empty meta.qps means empty qps */
    if (st.st_size == 0) {
        logger_trace(&qps->logger, 1, "qps_open() = %p", qps);
        return qps;
    }

    if (qps_load_meta(qps, priv, false)) {
        goto out_close;
    }
    logger_trace(&qps->logger, 1, "qps_open() = %p", qps);
    qps_dir_cleanup(qps, qps->generation - 2);
    return qps;

  out_close:
    qps_close(&qps);
    return NULL;
}

int __qps_check_consistency(const char *path, const char *name)
{
    struct stat st;
    qps_t      *qps;
    int         fd, res = 0;

    fd  = RETHROW(open(path, O_RDONLY));
    qps = qps_new(fd, name);

    if (fstatat(fd, "meta.qps", &st, 0) < 0) {
        res = logger_error(&qps->logger, "unable to stat meta.qps: %m");
        goto out_close;
    }
    /* empty meta.qps means empty qps */
    if (st.st_size == 0) {
        logger_trace(&qps->logger, 1, "qps_open() = %p", qps);
        goto out_close;
    }

    if ((res = qps_load_meta(qps, NULL, true)))
        goto out_close;
    logger_trace(&qps->logger, 1, "__qps_check_consistency() = %p", qps);

  out_close:
    qps_close(&qps);
    return res;
}

/** check if the given directory seems to hold a qps store.
 * \param[in]  path   path to the qps spool
 * \return
 *   - true if the path holds a "meta.qps" file
 *   - false else
 */
bool qps_exists(const char *path)
{
    char tmp[PATH_MAX];

    snprintf(tmp, sizeof(tmp), "%s/meta.qps", path);
    return access(path, R_OK | W_OK | X_OK) == 0 && access(tmp, R_OK) == 0;
}

/** \brief destroy a QPS in the given path.
 *
 * \param[in] path   the path to the qps directory
 * \return
 *   - -1 if one of the file couldn't be removed, or any other error occured.
 *   - 0 if all file from the QPS was destroyed.
 */
int qps_unlink(const char *path)
{
    struct dirent *de;
    int res = 0, fd;
    DIR *dir;

    fd  = RETHROW(open(path, O_RDONLY));
    dir = fdopendir(fd);
    if (!dir) {
        logger_error(&_G.logger, "unable to fdopendir `%s`: %m", path);
        p_close(&fd);
        return -1;
    }

    rewinddir(dir);
    while ((de = readdir(dir))) {
        const char *s = de->d_name;
        const char *e = path_extnul(s);

        if (strequal(".qps", e) || strequal(".qpz", e) || strequal(".qpt", e)) {
            logger_trace(&_G.logger, 1, "unlinkat(%s)", s);
            if (unlinkat(fd, s, 0)) {
                res = logger_error(&_G.logger, "unable to unlink %s", s);
                break;
            }
        }
    }
    closedir(dir);
    return res;
}

/** \brief create a qps store.
 *
 * \param[in]  path
 *   path to the qps spool. If it doesn't exist yet, it's created.
 *
 * \param[in]  name
 *   name of the qps spool; is used to create the QPS loggers (so must be
 *   compatible with logger names, and be unique).
 *
 * \param[in]  mode
 *   mode to use for the directory creation if needed (\see mkdir()).
 *
 * \return
 *   - NULL if it failed, errno may be consulted to know why to some extent
 *   - a pointer to the created qps object.
 */
qps_t *qps_create(const char *path, const char *name, mode_t mode,
                  const void *data, size_t dlen)
{
    qps_t *qps;
    int fd;
    qv_t(u32) t;

    RETHROW_NP(mkdir_p(path, mode));
    fd  = RETHROW_NP(open(path, O_RDONLY));
    qps = qps_new(fd, name);
    if (qps_lock(qps) < 0) {
        qps_close(&qps);
        return NULL;
    }

    qv_init(&t);
    x_write_meta(qps, 1, t, data, dlen);
    x_renameat(qps->dfd, "meta.qpt", qps->dfd, "meta.qps");
    x_fdatasync(qps->dfd);
    logger_trace(&qps->logger, 1, "qps_create() = %p", qps);
    return qps;
}

static void qps_snapshot_bg_done(el_t el, pid_t pid, int status, data_t data)
{
    qps_t *qps = data.ptr;

    if (!WIFEXITED(status) || WEXITSTATUS(status) != 0) {
        logger_panic(&qps->logger, "background snapshot failed");
    }

    qps->snap_el = NULL;

    thr_schedule_b(^{
        thr_syn_wait(&qps->snap_syn);

        thr_queue_b(thr_queue_main_g, ^{
            struct timeval end;

            el_unregister(&qps->snap_timer_el);
            logger_trace(&qps->tracing_logger, 1, "snapshot commited and "
                         "notified");

            qps_dir_cleanup(qps, qps->snap_gen);
            qps_unquarantine_nos(qps);

            for (int i = 0; i < qps->maps.len; i++) {
                qps_map_t *map = qps->maps.tab[i];

                if (!map)
                    continue;

                if (QPS_GEN_CMP(map->hdr.generation, >, qps->snap_gen))
                    continue;
                if (qps_map_is_pg(map)) {
                    map->hdr.generation = qps->snap_gen;
                    continue;
                }
                if (map->hdr.remaining == 0) {
                    qps_map_recycle(qps, map, i, true);
                } else
                if (map->hdr.generation == qps->snap_gen) {
                    uint32_t   remaining = map->hdr.remaining;
                    qps_map_t *m = qps_m_map_open(qps, map->hdr.mapno);

                    if (map != m) {
                        logger_panic(&qps->logger, "snapshot is inconsistent");
                    }
                    /* Some entries may have been deallocated since the
                     * beginning of the snapshot, so keep the remaining count
                     */
                    m->hdr.remaining = remaining;
                }
            }

            qps->snapshotting = false;
            lp_gettv(&end);
            logger_debug(&qps->tracing_logger, "snapshot done in %jdms",
                         timeval_diffmsec(&end, &qps->snap_start));
            qps->snap_notify(qps->snap_gen);
            Block_release_p(&qps->snap_notify);
        });
    });
}

static pid_t
qps_snapshot_bg(qps_t *qps, const void *data, size_t dlen,
                qv_t(u32) t, uint32_t generation)
{
    dir_lock_t dlock;
    pid_t pid;
    struct timeval begin, step_fork, step_end;

    lp_gettv(&begin);
    pid = ifork();
    if (pid < 0) {
        logger_panic(&qps->logger, "unable to fork snapshotter in the "
                     "background, %m");
    }
    if (pid > 0) {
        return pid;
    }
    _G.in_snapshot_fork = true;

    lp_gettv(&step_fork);

    if (qps_lock_snapshot(qps, &dlock) < 0) {
        logger_fatal(&qps->logger, "QPS: cannot take snapshotter lock");
    }

    for (int i = 0; i < qps->maps.len; i++) {
        struct timeval start, end;
        qps_map_t *map = qps->maps.tab[i];

        lp_gettv(&start);
        if (!map) {
            goto next;
        }

        if (!qps_map_is_pg(map) && map->hdr.generation == generation) {
            qps_map_m_snapshot(qps, map, generation);
            goto next;
        }

        if (!qps_map_is_pg(map) || qps_map_pg_is_all_free(qps, map)) {
            munmap(map, QPS_MAP_SIZE);
            goto next;
        }

        if (map->hdr.generation == generation) {
            qps_map_pg_snapshot(qps, map, generation);
        } else {
            /* map didn't change, hardlink the previous snapshot */
            char dst[32], src[32];

            snprintf(src, sizeof(src), "%08x.%08x.qpz",
                     map->hdr.mapno, map->hdr.generation);
            snprintf(dst, sizeof(dst), "%08x.%08x.qpz",
                     map->hdr.mapno, generation);
            x_linkat(qps->dfd, src, qps->dfd, dst, 0);
        }
        munmap(map, QPS_MAP_SIZE);

      next:
        lp_gettv(&end);
        logger_debug(&qps->tracing_logger, "snapshotting %d/%d (%jdms)",
                     i + 1, qps->maps.len, timeval_diffmsec(&end, &start));
    }
    x_write_meta(qps, generation, t, data, dlen);

    x_fdatasync(qps->dfd); // commit all file creations
    x_renameat(qps->dfd, "meta.qpt", qps->dfd, "meta.qps");
    x_fdatasync(qps->dfd); // commit rename
    lp_gettv(&step_end);
    logger_debug(&qps->tracing_logger, "snapshotted %d maps in %jd msec "
                 "(fork: %jd msec)", qps->maps.len,
                 timeval_diffmsec(&step_end, &begin),
                 timeval_diffmsec(&step_fork, &begin));
    unlockdir(&dlock);
    _exit(0);
}

/** \brief take a qps snapshot.
 *
 * This function is the most important one to use a QPS. Usually a QPS comes
 * with some kind of binary logs that allow to recreate a given state starting
 * from a QPS snapshot.
 *
 * When the binlog grows very large (or any other kind of reason), it's time
 * to take a snapshot. This will mark all the memory maps of the database as
 * read-only, and msync() them on disk. When this is done, \a notify is called
 * with 0 if the whole operation worked, -1 else.
 *
 * It is mandatory to flush and fsync any binlog you may have before you call
 * this function (checking that your fdatasync() worked of course). It's also
 * up to the caller to ensure that there isn't ever two concurrent
 * qps_snapshot running at the same time.
 *
 * When the notification block is called with a negative value, it means that
 * the file-system hasn't allowed us to fdatasync(). The binlog(s) should be
 * fdatasync()ed on a regular basis (either based on the size or the date of
 * the last fdatasync() or a combination thereof) meaning that it's probably
 * not critical if the snapshot failed. It's though probably a good idea to
 * switch to full read-only mode at the application level if possible, or
 * "crash".
 *
 * qps allocates memory maps on disk using sparse 256Mo files. fast snapshots
 * won't hurt file-system consumption that much, but will likely use a large
 * range of addressing space.
 *
 * \param[in]  qps      the qps object to work on
 * \param[in]  data
 *   pointer to opaque private metadata to serialize along the snapshot.
 * \param[in]  dlen     length of the opaque private metadata.
 * \param[in]  notify   the completion notification block.
 * \return
 *   the new generation of the qps object.
 */
uint32_t qps_snapshot(qps_t *qps, const void *data, size_t dlen,
                      void (^notify)(uint32_t))
{
    t_scope;
    struct timeval step_madvise, step_end;
    uint32_t  rec_pos;
    qv_t(u32) t;
    uint32_t  wait_for;

    assert (qps->snapshotting == false);

    qps->snap_gen = qps->generation;
    lp_gettv(&qps->snap_start);
    qps_gc_disable(qps);
    qps->snapshotting = true;
    qps->generation  += 2;
    qps->snap_notify = Block_copy(notify);

    logger_trace(&qps->logger, 1, "qps_snapshot(%p)", qps);
    t_qv_init(&t, 1024);
    p_clear(&qps->m, 1);

    {
        uint32_t  h_max = qps->handles_max;
        uint32_t  h_len = DIV_ROUND_UP(h_max, QPS_HANDLES_COUNT);
        uint32_t *hdata = qv_growlen(&t, 2 + h_len);

        hdata[0] = h_max;
        hdata[1] = qps->handles_freelist;

        for (size_t i = 0; i < h_len; i++) {
            hdata[2 + i] = qps_pg_of(qps->handles[i]);
        }
    }
    rec_pos = t.len;
    qv_append(&t, 0);

    for (int i = 0; i < qps->maps.len; i++) {
        qps_map_t *map = qps->maps.tab[i];
        qps_pghdr_t *hdrs;

        if (!map) {
            continue;
        }

        assert (QPS_GEN_CMP(qps->snap_gen, >=, map->hdr.generation));
        qps_map_protect(qps, map, PROT_READ);

        if (!qps_map_is_pg(map)) {
            if (map->hdr.generation == qps->snap_gen) {
                map->hdr.remaining  = map->hdr.allocated;
                map->hdr.disk_usage = 0;
            }

            if (map->hdr.remaining) {
                qv_append(&t, i | QPS_META_MAP_TLSF);
                qv_append(&t, map->hdr.remaining);
            }
            continue;
        }

        if (qps_map_pg_is_all_free(qps, map)) {
            madvise(&map[1], QPS_MAP_SIZE - QPS_PAGE_SIZE, MADV_DONTNEED);
            continue;
        }

        qv_append(&t, i | QPS_META_MAP_PAGED);
        qv_append(&t, 0);

        hdrs = qps->hdrs + map->hdr.mapno * QPS_MAP_PAGES;
        for (size_t pg = 1; pg < QPS_MAP_PAGES; pg += hdrs[pg].size) {
            uint16_t sz = hdrs[pg].size;

            assert (sz >= 1 && pg + sz <= QPS_MAP_PAGES);
            if (hdrs[pg].flags & QPS_BLK_FREE) {
                madvise(&map[pg], sz * QPS_PAGE_SIZE, MADV_DONTNEED);
            }
        }
    }
    t.tab[rec_pos] = (t.len - rec_pos) / 2;

    lp_gettv(&step_madvise);
    qps->snap_pid = qps_snapshot_bg(qps, data, dlen, t, qps->snap_gen);
    qps->snap_el = el_child_register(qps->snap_pid, &qps_snapshot_bg_done, qps);
    el_unref(qps->snap_el);

    /* If the disk write speed is lower than 16 MB/s, there is an issue.
     * Thus we need less than 16s per 256 MB map, so the max time is
     * 16 * qps->maps.len secondes.
     * In order to avoid any regression the max of this value and 1 hour is
     * used.
     */
    wait_for = MAX(3600, qps->maps.len * 16);
    qps->snap_timer_el = el_timer_register_blk(wait_for * 1000, 0, 0,
                                               ^(el_t ev){
        logger_fatal(&qps->logger, "qps: snapshot (generation %x) stuck for "
                     "more than %d sec", qps->snap_gen, wait_for);
    }, NULL);
    el_unref(qps->snap_timer_el);

    lp_gettv(&step_end);
    logger_trace(&qps->logger, 1, "snapshot: mmaps setup in %jd msec, "
                 "scheduled in %jd msec",
                 timeval_diffmsec(&step_madvise, &qps->snap_start),
                 timeval_diffmsec(&step_end, &qps->snap_start));
    return qps->generation;
}

/** Wait until an ongoing synchronization is done and notified.
 *
 * This function never fails.
 */
void qps_snapshot_wait(qps_t *qps)
{
    if (qps->snapshotting) {
        thr_syn_wait(&qps->snap_syn);

        if (qps->snap_el) {
            thr_schedule_b(^{
                int status;
                bool first = true;

                for (;;) {
                    int ret = waitpid(qps->snap_pid, &status, 0);

                    if (ret == qps->snap_pid) {
                        break;
                    } else
                    if (errno == ECHILD) {
                        /* XXX The child probably get collected by the
                         * el_child_register call that performs a waitpid(), but
                         * we may not have returned to the event loop since then,
                         * so the el didn't get fired. As a consequence, we get
                         * the status cached by the el_t.
                         */
                        assert (first);
                        status = el_child_get_status(qps->snap_el);
                        break;
                    }
                    first = false;
                }
                thr_queue_b(thr_queue_main_g, ^{
                    el_unregister(&qps->snap_el);
                    qps_snapshot_bg_done(NULL, qps->snap_pid, status,
                                         (data_t){ .ptr = qps });
                    MODULE_METHOD_RUN_INT(at_fork_on_child_terminated,
                                          qps->snap_pid);
                });
            });
        }

        while (qps->snapshotting || qps->snap_el) {
            MODULE_METHOD_RUN_VOID(consume_child_events);
            thr_queue_main_drain();
        }
    }
}

/** Copy meta.qps, and all the file linked inside.
 *
 * The copy is from the current db director, to @dfd_dst.
 *
 * The qps MUST not be snapshotting.
 *
 */
int qps_backup(qps_t *qps, int dfd_dst, bool link_as_copy)
{
    t_scope;
    struct qps_meta *meta;
    size_t meta_size;
    uint32_t *h_u32, *u32, *uend;
    uint32_t h_len;
    int ret = 0;

    THROW_ERR_IF(!qps || qps->dfd < 0 || dfd_dst < 0);
    THROW_ERR_IF(qps->snapshotting);

    /* Step 1: Look for linked files in meta.qps, and copy them. */
    /* Special case of empty meta.qps */
    {
        struct stat st;

        if (fstatat(qps->dfd, "meta.qps", &st, 0) < 0) {
            ret = logger_error(&qps->logger, "unable to stat meta.qps: %m");
            goto error;
        }
        if (st.st_size == 0) {
            int fd = openat(dfd_dst, "meta.qps",
                            O_CREAT | O_EXCL | O_RDWR, 0444);
            if (fd < 0) {
                ret = logger_error(&qps->logger, "unable to touch meta.qps");
                goto error;
            }
            p_close(&fd);
            return 0;
        }
    }

    RETHROW(qps_map_meta(qps, &meta, &meta_size));
    if (meta->osize == 0) {
        goto end;
    }

    u32  = t_new_raw(uint32_t, meta->osize / 4);
    uend = u32 + meta->osize / 4;
    if ((ret = qps_unlzo_data(qps, meta->data, meta->csize, meta->osize,
                              u32)) < 0)
    {
        goto err_unmap;
    }

    h_len = DIV_ROUND_UP(u32[0], QPS_HANDLES_COUNT);
    h_u32 = u32 + 2;
    u32 = h_u32 + h_len;

    if (u32 + 1 + u32[0] * 2 != uend) {
        ret = logger_error(&qps->logger,
                           "[backup] inconsistent meta.qps [1]");
        goto err_unmap;
    }
    u32++;

#define COPY_FILE(name)  do {                                               \
        if (link_as_copy) {                                                 \
            if (linkat(qps->dfd, name, dfd_dst, name, 0) < 0) {             \
                ret = logger_error(&qps->logger, "[backup] cannot link "    \
                                   "%s %m", name);                          \
                goto err_unmap;                                             \
            }                                                               \
        } else {                                                            \
            if (filecopyat(qps->dfd, name, dfd_dst, name) < 0) {            \
                ret = logger_error(&qps->logger, "[backup] cannot copy "    \
                                   "%s %m", name);                          \
                goto err_unmap;                                             \
            }                                                               \
        }                                                                   \
    } while (0)

    for (; u32 < uend; u32 += 2) {
        uint16_t no = u32[0];
        char buf[32];

        if (u32[0] & QPS_META_MAP_TLSF) {
            snprintf(buf, sizeof(buf), "%08x.qps", no);
        } else
        if (!(u32[0] & QPS_META_MAP_PAGED)) {
            ret = logger_error(&qps->logger, "[backup] inconsistent "
                               "meta.qps [6]");
            goto err_unmap;
        } else {
            snprintf(buf, sizeof(buf), "%08x.%08x.qpz", no, meta->generation);
        }
        COPY_FILE(buf);
    }

  end:
    /* Step 2: Write meta.qps */
    COPY_FILE("meta.qps");
#undef COPY_FILE

  err_unmap:
    x_munmap(meta, meta_size);

  error:
    return ret;
}

static void __qps_close(qps_t **qpsp, bool do_cleanup)
{
    qps_t *qps = *qpsp;

    if (qps) {
        logger_trace(&qps->logger, 2, "qps_closing(%p)", qps);
        el_unregister(&qps->gc_idle);
        qps_gc_disable(qps);
        thr_syn_wait(&qps->gc_syn);
        qps_snapshot_wait(qps);
        thr_syn_wait(&qps->snap_syn);
        thr_syn_wipe(&qps->gc_syn);
        thr_syn_wipe(&qps->snap_syn);

        tab_for_each_pos(i, &qps->maps) {
            qps_map_t *map = qps->maps.tab[i];
            char buf[32];

            if (map) {
                if (do_cleanup && !qps_is_ro(qps, map)) {
                    snprintf(buf, sizeof(buf), "%08x.qps", i);
                    logger_trace(&qps->logger, 1, "unlinkat(%s)", buf);
                    unlinkat(qps->dfd, buf, 0);
                }
                x_munmap(map, QPS_MAP_SIZE);
            }
        }
        tab_for_each_pos(i, &qps->omaps) {
            x_munmap(qps->omaps.tab[i], QPS_MAP_SIZE);
        }
        p_close(&qps->dfd);
        qv_wipe(&qps->maps);
        qv_wipe(&qps->smaps);
        qv_wipe(&qps->omaps);
        qv_wipe(&qps->no_free);
        qv_wipe(&qps->no_blocked);
        p_delete(&qps->handles);
        p_delete(&qps->hdrs);
        dlist_remove(&qps->qps_link);
        logger_trace(&qps->logger, 1, "unlockdir(.lock)");
        unlockdir(&qps->lock);
        logger_trace(&qps->logger, 1, "qps_close");
        logger_wipe(&qps->tracing_logger);
        logger_wipe(&qps->logger);
        p_delete(qpsp);
        MODULE_RELEASE(qps);
    }
}

/** close an allocated qps object.
 *
 * This function never fails. \see #qps_snapshot.
 */
void qps_close(qps_t **qpsp)
{
    __qps_close(qpsp, true);
}

/* }}} */
/* Tools {{{ */

static void qps_roots_sort(qps_roots_t *roots)
{
    qv_sort(qps_handle)(&roots->handles, ^(const qps_handle_t *a,
                                           const qps_handle_t *b) {
        return (int)(*a - *b);
    });

    qv_sort(qps_pg)(&roots->pages, ^(const qps_pg_t *a, const qps_pg_t *b) {
        return (int)(*a - *b);
    });
}

static void qps_get_roots(qps_t *qps, qps_roots_t *roots)
{
    int handle_pages = DIV_ROUND_UP(qps->handles_max, QPS_HANDLES_COUNT);

    tab_for_each_pos (p, &qps->maps) {
        qps_map_t *map = qps->maps.tab[p];

        if (!map || !qps_map_is_pg(map)) {
            continue;
        }

        for (uint32_t pg = 1; pg < QPS_MAP_PAGES;) {
            uint32_t     blk = (p << 16) | pg;
            qps_pghdr_t *hdr = &qps->hdrs[blk];
            uint32_t     sz  = hdr->size;

            assert (sz >= 1 && pg + sz <= QPS_MAP_PAGES);

            if (!(hdr->flags & QPS_BLK_FREE) && !hdr->handle) {
                bool is_handle_page = false;

                for (int i = 0; i < handle_pages; i++) {
                    if (blk == qps_pg_of(qps->handles[i])) {
                        is_handle_page = true;
                        break;
                    }
                }

                if (!is_handle_page) {
                    qv_append(&roots->pages, blk);
                }
            }
            pg += sz;
        }
    }

    for (uint32_t i = 1; i < qps->handles_max; i++) {
        qps_ptr_t *ptr = qps_handle_slot(qps, i);

        if (ptr->pgno != 0) {
            qv_append(&roots->handles, i);
        }
    }
    qps_roots_sort(roots);
}

static int qps_report_herr(qps_t *qps, qps_handle_t h, bool leak)
{
    if (leak) {
        qps_ptr_t *ptr = qps_handle_slot(qps, h);
        void      *p   = qps_handle_deref(qps, h);
        size_t     sz  = qps_sizeof(qps, p);

        logger_error(&qps->logger, "leak: handle %d [p:%p, ptr:"QPS_PTR_FMT", "
                     "sz:%zd/%zx]", h, p, QPS_PTR_ARG(*ptr), sz, sz);
    } else {
        logger_error(&qps->logger, "invalid: freed handle %d referenced", h);
    }
    return 1;
}

static int qps_report_pgerr(qps_t *qps, qps_pg_t pg, bool leak)
{
    if (leak) {
        void    *p = qps_pg_deref(qps, pg);
        uint32_t n = qps->hdrs[pg].size;

        logger_error(&qps->logger, "leak: page(s) "QPS_PG_FMT".."QPS_PG_FMT" "
                     "[p:%p, n:%d]", QPS_PG_ARG(pg), QPS_PG_ARG(pg + n), p, n);
    } else {
        logger_error(&qps->logger, "invalid: freed map "QPS_PG_FMT" referenced",
                     QPS_PG_ARG(pg));
    }
    return 1;
}

bool qps_check_leaks(qps_t *qps, qps_roots_t *roots)
{
    qps_roots_t actual_roots;
    int pos, leakh = 0, leakp = 0;

    qps_roots_init(&actual_roots);
    qps_get_roots(qps, &actual_roots);
    qps_roots_sort(roots);

    /* Check leak in handles */
    pos = 0;
    tab_for_each_pos (act_pos, &actual_roots.handles) {
        qps_handle_t h = actual_roots.handles.tab[act_pos];

        while (pos < roots->handles.len && roots->handles.tab[pos] < h) {
            leakh += qps_report_herr(qps, roots->handles.tab[pos++], false);
        }

        if (pos < roots->handles.len && roots->handles.tab[pos] == h) {
            pos++;
        } else {
            leakh += qps_report_herr(qps, h, true);
        }
    }
    while (pos < roots->handles.len) {
        leakh += qps_report_herr(qps, roots->handles.tab[pos++], false);
    }

    /* Check leak in pages */
    pos = 0;
    tab_for_each_pos (act_pos, &actual_roots.pages) {
        qps_pg_t pg = actual_roots.pages.tab[act_pos];

        while (pos < roots->pages.len && roots->pages.tab[pos] < pg) {
            leakp += qps_report_pgerr(qps, roots->pages.tab[pos++], false);
        }

        if (pos < roots->pages.len && pg == roots->pages.tab[pos]) {
            pos++;
        } else {
            leakp += qps_report_pgerr(qps, pg, true);
        }
    }
    while (pos < roots->pages.len) {
        leakp += qps_report_pgerr(qps, roots->pages.tab[pos++], false);
    }

    qps_roots_wipe(&actual_roots);
    if (leakh > 0) {
        logger_error(&qps->logger, "leak: %d handles among %d", leakh,
                     actual_roots.handles.len);
    }
    if (leakp > 0) {
        logger_error(&qps->logger, "leak: %d pages among %d", leakp,
                     actual_roots.pages.len);
    }
    return leakh + leakp;
}

void qps_get_usage(const qps_t *qps, struct qps_stats *st)
{
    p_clear(st, 1);

    for (int i = 0; i < qps->maps.len; i++) {
        qps_map_t *map = qps->maps.tab[i];

        if (!map)
            continue;
        st->n_maps++;
        if (qps_map_is_pg(map)) {
            qps_pghdr_t *hdrs = qps->hdrs + (i << 16);

            for (uint32_t pg = 1; pg < QPS_MAP_PAGES; pg += hdrs[pg].size) {
                if (!(hdrs[pg].flags & QPS_BLK_FREE)) {
                    st->pages++;
                    st->n_pages += hdrs[pg].size;
                } else {
                    st->pages_free++;
                    st->n_pages_free += hdrs[pg].size;
                }
            }
        } else
        if (qps_is_ro(qps, map)) {
            st->ro_allocs += map->hdr.remaining;
        } else {
            st->rw_allocs += map->hdr.allocated;
        }
    }
}

/* }}} */

static int qps_initialize(void *sighandler)
{
    struct sigaction prev;
    struct sigaction act = {
        .sa_sigaction = qps_on_segfault,
        .sa_flags     = SA_SIGINFO,
    };

    sigfillset(&act.sa_mask);
    sigaction(SIGSEGV, &act, &prev);
    sigaction(SIGBUS, &act, NULL);
    _G.sighandler = prev.sa_sigaction;
    return 0;
}

static int qps_shutdown(void)
{
    return 0;
}

MODULE_BEGIN(qps)
    MODULE_DEPENDS_ON(thr);
MODULE_END()

#if defined(__has_asan) && !__CLANG_PREREQ(5, 0)
const char *__asan_default_options(void);

__attribute__((visibility("default")))
const char *__asan_default_options(void)
{
    return "allow_user_segv_handler=1";
}
#endif

/** \} */
/* Tests {{{ */

#include "z.h"

static int run_snapshot(qps_t *qps)
{
    qps_snapshot(qps, NULL, 0, ^(uint32_t i) { });
    return 0;
}

Z_GROUP_EXPORT(qps)
{
    const char S[] = "abcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQSRT";
    qps_handle_t handle1, handle2, handle3;

    MODULE_REQUIRE(qps);

#define Z_CHECK_ALLOC(handle, size)  ({                                      \
        char *__data = qps_alloc(qps, &handle, size);                        \
                                                                             \
        Z_ASSERT_P(__data);                                                  \
        Z_ASSERT_GE(qps_sizeof(qps, __data), (size_t)size);                  \
                                                                             \
        __data;                                                              \
    })

#define Z_CHECK_ALLOC_AND_FILL(handle, size)  do {                           \
        char *__data2 = Z_CHECK_ALLOC(handle, size);                         \
        int __remain =  qps_sizeof(qps, __data2);                            \
                                                                             \
        while (__remain > 0) {                                               \
            int __to_write = MIN(__remain, countof(S) - 1);                  \
            memcpy(__data2, S, __to_write);                                  \
            __remain -= __to_write;                                          \
            __data2   += __to_write;                                         \
        }                                                                    \
    } while (0)

#define Z_CHECK_HANDLE(handle, len)  ({                                      \
        char *__data = qps_handle_deref(qps, handle);                        \
                                                                             \
        Z_ASSERT_GE(qps_sizeof(qps, __data), (size_t)len);                   \
        __data;                                                              \
    })

#define Z_CHECK_HANDLE_FILLED(handle, len)  do {                             \
        const char *__data2 = Z_CHECK_HANDLE(handle, len);                   \
        size_t __remain = (len);                                             \
                                                                             \
        while (__remain > 0) {                                               \
            int __to_read = MIN(__remain, countof(S) - 1);                   \
            Z_ASSERT_EQUAL(S, __to_read, __data2, __to_read);                \
            __remain -= __to_read;                                           \
            __data2  += __to_read;                                           \
        }                                                                    \
    } while (0)

#define Z_CHECK_REOPEN(_name, Cleanup)  do {                                 \
        __qps_close(&qps, Cleanup);                                          \
        qps = qps_open(z_tmpdir_g.s, _name, NULL);                           \
        Z_ASSERT_P(qps);                                                     \
    } while (0)

    Z_TEST(nr_20110105, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110105", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 24);
        Z_CHECK_ALLOC_AND_FILL(handle2, 42);
        Z_CHECK_ALLOC_AND_FILL(handle3, 24);

        Z_CHECK_HANDLE_FILLED(handle1, 24);
        Z_CHECK_HANDLE_FILLED(handle2, 42);
        Z_CHECK_HANDLE_FILLED(handle3, 24);

        Z_CHECK_REOPEN("nr_20110105", true);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20110107_1, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110107_1", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 24);

        Z_HELPER_RUN(run_snapshot(qps));

        Z_CHECK_ALLOC_AND_FILL(handle2, 42);

        Z_CHECK_HANDLE_FILLED(handle1, 24);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        Z_CHECK_REOPEN("nr_20110107_1", true);
        Z_CHECK_ALLOC_AND_FILL(handle1, 24);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20110107_2, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110107_2", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 24);

        Z_HELPER_RUN(run_snapshot(qps));
        qps_snapshot_wait(qps);

        Z_CHECK_ALLOC_AND_FILL(handle2, 42);

        Z_CHECK_HANDLE_FILLED(handle1, 24);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        Z_CHECK_REOPEN("nr_20110107_2", true);
        Z_CHECK_HANDLE_FILLED(handle1, 24);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20110107_3, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110107_3", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 24);

        Z_HELPER_RUN(run_snapshot(qps));

        Z_CHECK_ALLOC_AND_FILL(handle2, 42);

        qps_snapshot_wait(qps);

        Z_CHECK_HANDLE_FILLED(handle1, 24);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        Z_CHECK_REOPEN("nr_20110107_3", true);
        Z_CHECK_HANDLE_FILLED(handle1, 24);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20110203, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110203", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 120);
        Z_CHECK_ALLOC_AND_FILL(handle2, 120);
        qps_free(qps, handle2);

        Z_CHECK_HANDLE_FILLED(handle1, 120);

        Z_HELPER_RUN(run_snapshot(qps));

        Z_CHECK_ALLOC_AND_FILL(handle2, 42);
        Z_CHECK_HANDLE_FILLED(handle1, 120);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        qps_snapshot_wait(qps);
        Z_CHECK_HANDLE_FILLED(handle1, 120);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        Z_HELPER_RUN(run_snapshot(qps));
        Z_CHECK_HANDLE_FILLED(handle1, 120);
        Z_CHECK_HANDLE_FILLED(handle2, 42);

        Z_CHECK_REOPEN("nr_20110203", true);
        Z_CHECK_HANDLE_FILLED(handle1, 120);
        Z_CHECK_HANDLE_FILLED(handle2, 42);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20110302, "") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20110302", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 36);
        Z_CHECK_ALLOC_AND_FILL(handle2, 36);

        qps_free(qps, handle1);
        Z_CHECK_HANDLE_FILLED(handle2, 36);

        Z_CHECK_REOPEN("nr_20110302", true);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20120824_1, "map emptied concurrently to snapshot") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20120824_1", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 36);

        Z_HELPER_RUN(run_snapshot(qps));
        IGNORE(qps_handle_w_deref(qps, handle1));
        qps_snapshot_wait(qps);

        Z_CHECK_REOPEN("nr_20120824_1", true);
        Z_CHECK_HANDLE_FILLED(handle1, 36);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20120824_2, "map emptied concurrently to snapshot") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20120824_2", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 36);

        Z_HELPER_RUN(run_snapshot(qps));
        qps_free(qps, handle1);
        qps_snapshot_wait(qps);

        Z_CHECK_REOPEN("nr_20120824_2", true);
        Z_CHECK_HANDLE_FILLED(handle1, 36);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20120827_1, "map emptied then reused after snapshot") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20120827_1", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 36);
        Z_HELPER_RUN(run_snapshot(qps));
        qps_free(qps, handle1);
        qps_snapshot_wait(qps);

        memset(Z_CHECK_ALLOC(handle1, 24), 0, 24);

        Z_CHECK_REOPEN("nr_20120827_1", true);
        Z_CHECK_HANDLE_FILLED(handle1, 36);
        qps_close(&qps);
    } Z_TEST_END;

    Z_TEST(nr_20120827_2, "map emptied then reused after snapshot") {
        qps_t *qps = qps_create(z_tmpdir_g.s, "nr_20120827_2", 0755, NULL, 0);

        Z_CHECK_ALLOC_AND_FILL(handle1, 36);
        Z_HELPER_RUN(run_snapshot(qps));
        qps_free(qps, handle1);
        qps_snapshot_wait(qps);

        memset(Z_CHECK_ALLOC(handle1, 24), 0, 24);

        Z_CHECK_REOPEN("nr_20120827_2", false);
        Z_CHECK_HANDLE_FILLED(handle1, 36);
        qps_close(&qps);
    } Z_TEST_END;
    MODULE_RELEASE(qps);
}
Z_GROUP_END;

/* }}} */
